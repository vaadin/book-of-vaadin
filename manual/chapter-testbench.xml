<?xml version="1.0" encoding="UTF-8"?>
<!-- ====================================================================== -->
<!-- Copyright 2000-2012 Vaadin Ltd                                         -->
<!-- All Rights Reserved                                                    -->
<!-- This work is licensed under a Creative Commons Attribution-NoDerivs    -->
<!-- License (CC-BY-ND) Version 3.0. Full license text is available at:     -->
<!-- http://creativecommons.org/licenses/by-nd/3.0/legalcode                -->
<!-- ====================================================================== -->

<chapter xml:id="testbench">
	<title>Vaadin TestBench</title>

    <para>
        This chapter describes the installation and use of the Vaadin TestBench.
    </para>

    <section xml:id="testbench.overview">
        <title>Overview</title>

        <para>
            Quality assurance is one of the cornerstones of modern software
            development. Extending throughout the entire development process, quality
            assurance is the thread that binds the end product to the requirements. In
            iterative development processes, with ever shorter release cycles and
            continuous integration, the role of regression testing is central. The special
            nature of web applications creates many unique requirements for regression
            testing.
        </para>

        <para>
            In a typical situation, you are developing a web application with Vaadin and
            want to ensure that only intended changes occur in its behaviour after
            modifying the code, without testing the application manually every time. There
            are two basic ways of detecting such regressions. Screenshots are the
            strictest way, but often just checking the displayed values in the HTML is
            better if you want to allow some flexibility for themeing, for example. You
            may also want to generate many different kinds of inputs to the application
            and check that they produce the desired outputs.
        </para>

		<figure xml:id="figure.testbench.webdriver">
			<title>Controlling the Browser with WebDriver</title>
			<mediaobject>
				<imageobject role="html">
					<imagedata align="center" fileref="img/testbench/webdriver-use-lo.png"/>
				</imageobject>
				<imageobject role="fo">
					<imagedata scale="70" smallscale="100%" align="center" fileref="img/testbench/webdriver-use-hi.png"/>
				</imageobject>
			</mediaobject>
		</figure>

        <para>
            Vaadin TestBench utilizes the Selenium WebDriver to control the browser from
            Java code, as illustrated in <xref linkend="figure.testbench.webdriver"/>. It
            can open a new browser window to start the application, interact with the
            components for example by clicking them, and then get the HTML element values.
        </para>

        <para>
            You can develop such WebDriver unit tests along your application code, for
            example with JUnit, which is a widely used Java unit testing framework. You
            can also use a recorder that runs in the browser to create JUnit test case
            stubs, which you can then refine further with Java. You can run the tests as
            many times as you want in your workstation or in a distributed grid setup.
        </para>

		<figure xml:id="figure.testbench.workflow">
			<title>TestBench Workflow</title>
			<mediaobject>
				<imageobject role="html">
					<imagedata align="center" fileref="img/testbench/tt-workflow-lo.png"/>
				</imageobject>
				<imageobject role="fo">
					<imagedata scale="130" smallscale="90%" align="center" fileref="img/testbench/tt-workflow-hi.png"/>
				</imageobject>
			</mediaobject>
		</figure>

        <para>The main features of Vaadin TestBench are:</para>

        <itemizedlist>
            <listitem>
                <para>Record JUnit test case stubs in browser</para>
            </listitem>
            <listitem>
                <para>Develop tests in Java with the WebDriver</para>
            </listitem>
            <listitem>
                <para>Validate UI state by assertions and screen capture comparison</para>
            </listitem>
            <listitem>
                <para>Screen capture comparison with difference highlighting</para>
            </listitem>
            <listitem>
                <para>Distributed test grid for running tests</para>
            </listitem>
            <listitem>
                <para>Integration with unit testing</para>
            </listitem>
            <listitem>
                <para>Test with browsers on mobile devices</para>
            </listitem>
        </itemizedlist>

        <para>
            Execution of tests can be distributed over a grid of test nodes, which speeds
            up testing. The grid nodes can run different operating systems and have
            different browsers installed. In a minimal setup, such as for developing the
            tests, you can use Vaadin TestBench on just a single computer.
        </para>

        <simplesect>
            <title>Based on Selenium</title>

            <para>
                Vaadin TestBench is based on the Selenium web browser automation
                library. With the Selenium WebDriver API, you can control browsers
                straight from Java code. The TestBench Recorder is based on the Selenium
                IDE. 
            </para>

            <para>
                Selenium is augmented with Vaadin-specific extensions, such as:
            </para>

            <itemizedlist>
                <listitem>Proper handling of Ajax-based communications of Vaadin</listitem>
                <listitem>Exporting test case stubs from the Recorder</listitem>
                <listitem>Performance testing of Vaadin applications</listitem>
                <listitem>Screen capture comparison</listitem>
                <listitem>Finding HTML elements using a Vaadin selector</listitem>
            </itemizedlist>
        </simplesect>

        <simplesect xml:id="testbench.overview.components">
            <title>TestBench Components</title>

            <para>
                The main components of Vaadin TestBench are:
            </para>

            <itemizedlist>
                <listitem>
                    <para>Vaadin TestBench Java Library</para>
                </listitem>
                <listitem>
                    <para>Vaadin TestBench Recorder</para>
                </listitem>
            </itemizedlist>

            <para>
                The library includes WebDriver, which provides API to control a browser like a
                user would. This API can be used to build tests, for example, with JUnit.  It
                also includes the grid hub and node servers, which you can use to run tests in
                a grid configuration.
            </para>

            <para>
                The Vaadin TestBench Recorder is helpful for creating test case stubs. It is a
                Firefox extension that you install in your browser. It has a control panel to
                record test cases and play them back. You can play the test cases right in the
                recorder. You can then export the tests as JUnit tests, which you can edit
                further and then execute with the WebDriver.
            </para>

            <para>
                Vaadin TestBench Library provides the central control logic for:
            </para>

            <itemizedlist>
                <listitem>
                    <para>
                        Executing tests with the WebDriver
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Additional support for testing Vaadin-based applications
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Comparing screen captures with reference images
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Distributed testing with grid node and hub services
                    </para>
                </listitem>
            </itemizedlist>
        </simplesect>

        <simplesect xml:id="testbench.overview.requirements">
            <title>Requirements</title>

            <para>
                Requirements for recording test cases with Vaadin TestBench Recorder:
            </para>

            <itemizedlist>
                <listitem>
                    <para>Mozilla Firefox</para>
                </listitem>
            </itemizedlist>

            <para>
                Requirements for running tests:
            </para>

            <itemizedlist>
                <listitem>
                    <para>Java JDK 1.6 or newer</para>
                </listitem>
                <listitem>
                    <para>Browsers installed on test nodes as supported by Selenium WebDriver</para>
                    <itemizedlist>
                        <listitem>Google Chrome</listitem>
                        <listitem>Internet Explorer</listitem>
                        <listitem>Mozilla Firefox (ESR version recommended)</listitem>
                        <listitem>Opera</listitem>
                        <listitem>Mobile browsers: Android, iPhone</listitem>
                    </itemizedlist>
                </listitem>

                <listitem>
                    <para>
                        A build system, such as Ant or Maven, to automate execution of
                        tests during build process (recommended)
                    </para>
                </listitem>
            </itemizedlist>

            <para>
                Note that running tests on an Extended Support Release (ESR) version of
                Firefox is recommended because of the frequent release cycle of Firefox,
                which often cause tests to fail. Download an ESR release of Firefox from
                <link
                xlink:href="http://www.mozilla.org/en-US/firefox/organizations/all.html">http://www.mozilla.org/en-US/firefox/organizations/all.html</link>.
                Install it alongside your normal Firefox install (do not overwrite).
            </para>

            <para>
                For Mac OS X, note the issue mentioned in <xref
                linkend="testbench.known-issues.firefox-mac"/>.
            </para>
        </simplesect>

        <simplesect>
            <title>Continuous Integration Compatibility</title>
                
            <para>
                Continuous integration means automatic compilation and testing of
                applications frequently, typically at least daily, but ideally every time
                when code changes are committed to the source repository. This practice
                allows catching integration problems early and finding the changes that
                first caused them to occur.
            </para>

            <para>
                You can make unit tests with Vaadin TestBench just like you would do any
                other Java unit tests, so they work seamlessly with continuous integration
                systems. Vaadin TestBench is tested to work with at least TeamCity and
                Hudson/Jenkins build management and continuous integration servers, which
                all have special support for the JUnit unit testing framework.
            </para>
        </simplesect>

        <simplesect>
            <title>Licensing and Trial Period</title>

            <para>
                You can download Vaadin TestBench from Vaadin Directory and try it out for
                a free 30-day trial period, after which you are required to acquire the
                needed licenses. You can purchase licenses from the Directory.  A license
                for Vaadin TestBench is also included in the Vaadin Pro Account
                subscription.
            </para>
        </simplesect>
    </section>

    <section xml:id="testbench.installation">
        <title>Installing Vaadin TestBench</title>

        <para>
            Installation of Vaadin TestBench covers the following tasks:
        </para>

        <itemizedlist>
            <listitem>
                <para>Download and unpack the Vaadin TestBench installation package</para>
            </listitem>
            <listitem>
                <para>Install Vaadin TestBench Recorder</para>
            </listitem>
            <listitem>
                <para>Install Vaadin TestBench Library</para>
            </listitem>
        </itemizedlist>

        <para>
            Which modules you need to install depends on whether you are developing tests
            or running existing tests. Two basic installation types are covered in these
            instructions:
        </para>

        <itemizedlist>
            <listitem>
                <para>Test development installation on a workstation</para>
            </listitem>
            <listitem>
                <para>Distributed grid installation</para>
            </listitem>
        </itemizedlist>

        <section xml:id="testbench.installation.development">
            <title>Test Development Installation</title>

            <para>
                In a typical test development setup, you install Vaadin TestBench on a
                workstation. You can use the TestBench Recorder to record test cases and
                export them as JUnit test case stubs. This is especially recommended if
                you are new to Vaadin TestBench and do not want to code from scratch. You
                can install the Recorder in Firefox as described in <xref
                linkend="testbench.installation.recorder"/>.
            </para>

            <para>
                You may find it convenient to develop and execute tests under an IDE such
                as Eclipse. The special support for running JUnit test cases in Eclipse is
                described in <xref linkend="testbench.development.eclipse"/>.
            </para>

            <para>
                In such a test development setup, you do not need a grid hub or
                nodes. However, if you develop tests for a grid, you can run the tests,
                the grid hub, and one node all in your development workstation. A
                distributed setup is described in the following section.
            </para>
        </section>

        <section xml:id="testbench.installation.distributed">
            <title>A Distributed Testing Environment</title>

            <para>
                Vaadin TestBench supports distributed execution of tests in a grid. A test
                grid consists of the following categories of hosts:
            </para>

            <itemizedlist>
                <listitem>
                    <para>One or more test servers executing the tests</para>
                </listitem>
                <listitem>
                    <para>A grid hub</para>
                </listitem>
                <listitem>
                    <para>Grid nodes</para>
                </listitem>
            </itemizedlist>

            <para>
                The components of a grid setup are illustrated in <xref
                    linkend="figure.testbench.architecture"/>.
            </para>

            <figure xml:id="figure.testbench.architecture">
                <title>Vaadin TestBench Grid Setup</title>
                <mediaobject>
                    <imageobject role="html">
                        <imagedata align="center" fileref="img/testbench/tt-architecture-simple-lo.png"/>
                    </imageobject>
                    <imageobject role="fo">
                        <imagedata scale="100" smallscale="100%" align="center" fileref="img/testbench/tt-architecture-simple-hi.png"/>
                    </imageobject>
                </mediaobject>
            </figure>

            <para>
                The grid hub is a service that handles communication between the JUnit
                test runner and the nodes. The nodes are services that perform the actual
                execution of test commands in the browser.
            </para>

            <para>
                The hub requires very little resources, so you would typically run it
                either in the test server or on one of the nodes. You can run the tests,
                the hub, and one node all in one host, but in a fully distributed setup,
                you install the Vaadin TestBench components on separate hosts.
            </para>

            <para>
                Controlling browsers over a distributed setup requires using a remote
                WebDriver.  Grid development and use of the hub and nodes is described in
                <xref linkend="testbench.grid"/>.
            </para>
        </section>

        <section xml:id="testbench.installation.downloading">
            <title>Downloading and Unpacking the Installation Package</title>

            <para>
                First, download the installation package
                <filename>vaadin-testbench-&version.testbench;.zip</filename> and extract
                the installation package where you can find it.
            </para>

            <simplesect>
                <title>Windows</title>

                <para>
                    In Windows, use the default ZIP decompression feature to extract the
                    package into your chosen directory, for example,
                    <filename>C:\dev</filename>.
                </para>

                <warning>
                    <title>Windows Zip Decompression Problem</title>

                    <para>
                        The default decompression program in Windows XP and Vista as well
                        as some versions of WinRAR cannot unpack the installation package
                        properly in certain cases. Decompression can result in an error
                        such as: "The system cannot find the file specified." This can
                        happen because the default decompression program is unable to
                        handle long file paths where the total length exceeds 256
                        characters. This can occur, for example, if you try to unpack the
                        package under Desktop. You should unpack the package directly into
                        <filename>C:\dev</filename> or some other short path or use
                        another decompression program.
                    </para>
                </warning>
            </simplesect>

            <simplesect>
                <title>Linux, MacOS X, and other UNIX</title>

                <para>
                    In Linux, Mac OS X, and other UNIX-like systems, you can use Info-ZIP
                    or other ZIP software with the command:
                </para>

                <screen><prompt>$</prompt> <command>unzip</command> <parameter>vaadin-testbench-&version.testbench;.zip</parameter></screen>

                <para>
                    The contents of the installation package will be extracted under the
                    current directory.
                </para>

                <para>
                    In Mac OS X, you can also double-click the package to extract it under
                    the current folder in a folder with the same name as the package.
                </para>
            </simplesect>
        </section>

        <section xml:id="testbench.installation.contents">
            <title>Installation Package Contents</title>

            <para>
                The installation package contains the following:
            </para>

            <variablelist>
                <varlistentry>
                    <term><filename>documentation</filename></term>
                    <listitem>
                        <para>
                            The documentation folder contains the TestBench library API documentation,
                            a PDF excerpt of this chapter of Book of Vaadin, and the
                            license.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><filename>example</filename></term>
                    <listitem>
                        <para>
                            The example folder provides TestBench examples. An example
                            Maven configuration POM is given, as well as the JUnit test
                            Java source files. For a description of the contents, see
                            <xref linkend="testbench.installation.examples"/>.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><filename>maven</filename></term>
                    <listitem>
                        <para>
                            The Maven folder contains version of the Vaadin TestBench
                            libraries that you can install in your local Maven
                            repository. Please follow the instructions in <xref
                            linkend="testbench.development.maven"/>.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><filename>vaadin-testbench-recorder</filename></term>
                    <listitem>
                        <para>
                            This folder constains the Vaadin TestBench Recorder, which you
                            can install in Firefox. Please follow the instructions in
                            <xref linkend="testbench.installation.recorder"/>.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><filename>vaadin-testbench-standalone-&version.testbench;.jar</filename></term>
                    <listitem>
                        <para>
                            This is the Vaadin TestBench library. It is a standalone
                            library that includes the Selenium WebDriver and many other
                            required libraries. The library includes the sources and the
                            JavaDoc.
                        </para>
                    </listitem>
                </varlistentry>
            </variablelist>
        </section>

        <section xml:id="testbench.installation.examples">
            <title>Example Contents</title>

            <para>
                The <filename>example/maven</filename> folder provides a number of
                examples for using Vaadin TestBench. The source code for the application
                to be tested, a desktop calculator application, is given in the
                <filename>src/main/java</filename> subfolder.
            </para>

            <para>
                The tests examples given under the <filename>src/test/java</filename>
                subfolder, in the <filename>com/vaadin/testbenchexample</filename> package
                subfolder, are as follows:
            </para>

            <variablelist>
                <varlistentry>
                    <term><filename>SimpleCalculatorITCase.java</filename></term>
                    <listitem>
                        <para>
                            Demonstrates the basic use of WebDriver. Interacts with the
                            buttons in the user interface by clicking them and checks the
                            resulting value. Uses <methodname>By.id()</methodname> to
                            access the elements.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><filename>LoopingCalculatorITCase.java</filename></term>
                    <listitem>
                        <para>
                            Otherwise as the simple example, but shows how to use looping
                            to produce programmatic repetition to create a complex use
                            case.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><filename>ScreenshotITCase.java</filename></term>
                    <listitem>
                        <para>
                            Shows how to compare screenshots, as described in <xref
                            linkend="testbench.screenshots"/>. Some of the test cases
                            include random input, so they require masked screenshot
                            comparison to mask the random areas out.
                        </para>

                        <para>
                            The example is ignored by default with an
                            <literal>@Ignore</literal> annotation, because the included
                            images were taken with a specific browser on a specific
                            platform, so if you use another environment, they will
                            fail. If you enable the test, you will need to run the tests,
                            copy the error images to the reference screenshot folder, and
                            mask out the areas with the alpha channel, as described in
                            <xref linkend="testbench.screenshot.comparison"/>.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><filename>SelectorExamplesITCase.java</filename></term>
                    <listitem>
                        <para>
                            This example shows how to use different selectors:
                        </para>

                        <itemizedlist>
                            <listitem><methodname>By.id()</methodname> - selecting by identifier</listitem>
                            <listitem><methodname>By.xpath()</methodname> - selecting by an XPath expression</listitem>
                        </itemizedlist>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><filename>VerifyExecutionTimeITCase.java</filename></term>
                    <listitem>
                        <para>
                            Shows how to time the execution of a test case and how to
                            report it.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><filename>AdvancedCommandsITCase.java</filename></term>
                    <listitem>
                        <para>
                            Demonstrates how to test tooltips (<xref
                            linkend="testbench.development.tooltip"/>) and context
                            menus. Uses component IDs, XPath expressions, as well as CSS
                            selectors to find the elements to check.
                        </para>
                    </listitem>
                </varlistentry>
            </variablelist>

            <para>
                For information about running the examples with Maven, see <xref
                linkend="testbench.development.maven"/>.
            </para>
        </section>

        <section xml:id="testbench.installation.recorder">
            <title>Installing the Recorder</title>

            <para>
                You can use the Vaadin TestBench Recorder in a test development
                environment to record test cases and to export them as JUnit test case
                stubs, which you can then develop further. This gives you a quick start
                when you are learning to use TestBench. Later you can use the Recorder to
                identify the HTML DOM paths of the user interface elements which you want
                to test.
            </para>

            <para>
                After extracting the files from the installation package, do the following:
            </para>

            <orderedlist>
                <listitem>
                    <para>Change to the <filename>vaadin-testbench-recorder</filename> directory under the installation directory.</para>
                </listitem>
                <listitem>
                    <para>Open Mozilla Firefox</para>
                </listitem>
                <listitem>
                    <para>
                        Either drag and drop the
                        <filename>vaadin-testbench-recorder-&version.testbench;.xpi</filename>
                        to an open Firefox window or open it from the menu with
                        <menuchoice><guimenu>File</guimenu><guimenuitem>Open
                        File</guimenuitem></menuchoice>.
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Firefox will ask if you want to install the TestBench Recorder extension. Click
                        <guibutton>Install</guibutton>.
                    </para>

                    <figure xml:id="figure.testbench.installation.recorder">
                        <title>Installing Vaadin TestBench Recorder</title>
                        <mediaobject>
                            <imageobject role="html">
                                <imagedata align="center" fileref="img/testbench/screenshots/tt-recorder-install.png"/>
                            </imageobject>
                            <imageobject role="fo">
                                <imagedata scale="90" smallscale="100%" align="center" fileref="img/testbench/screenshots/tt-recorder-install.png"/>
                            </imageobject>
                        </mediaobject>
                    </figure>
                </listitem>
                <listitem>
                    <para>
                        After the installation of the add-on is finished, Firefox offers
                        to restart. Click <guibutton>Restart Now</guibutton>.
                    </para>
                </listitem>
            </orderedlist>

            <para>
                Installation of a new version of Vaadin TestBench Recorder will
                overwrite an existing previous version.
            </para>

            <para>
                After Firefox has restarted, navigate to a Vaadin application for which
                you want to record test cases, such as <ulink
                url="http://demo.vaadin.com/sampler">http://demo.vaadin.com/sampler</ulink>.
            </para>
        </section>

        <section xml:id="testbench.installation.browserdrivers">
            <title>Installing Browser Drivers</title>
                
            <para>
                Whether developing tests with the WebDriver in the workstation or running
                tests in a grid, using some browsers requires that a browser driver is
                installed.
            </para>

            <orderedlist>
                <listitem>
                    <para>Download the latest browser driver</para>

                    <itemizedlist>
                        <listitem>
                            <para>
                                Internet Explorer (Windows only) - install <filename>IEDriverServer.exe</filename> from:
                            </para>
                            <para>
                                <link
                                    xlink:href="http://code.google.com/p/selenium/downloads/list">http://code.google.com/p/selenium/downloads/list</link>
                            </para>
                        </listitem>
                        <listitem>
                            <para>
                                Chrome - install ChromeDriver (a part of the Chromium
                                project) for your platform from:
                            </para>
                            <para>
                                <link
                                    xlink:href="http://code.google.com/p/chromedriver/downloads/list">http://code.google.com/p/chromedriver/downloads/list</link>
                            </para>
                        </listitem>
                    </itemizedlist>
                </listitem>

                <listitem>
                    Add the driver executable to PATH <emphasis>or</emphasis> define it as
                    a system property in the application using WebDriver locally, or in
                    distributed use give it as a command-line parameter to the grid node
                    service, as described in <xref linkend="testbench.grid.node"/>.
                </listitem>
            </orderedlist>
        </section>

        <section xml:id="testbench.installation.testnode">
            <title>Test Node Configuration</title>

            <para>
                If you are running the tests in a grid environment, you need to make some
                configuration to the test nodes to get more stable results.
            </para>

            <para>
                Further configuration is provided in command-line parameters when starting
                the node services, as described in <xref linkend="testbench.grid.node"/>.
            </para>

            <section xml:id="testbench.installation.testnode.os-settings">
                <title>Operating system settings</title>

                <para>
                    Make any operating system settings that might interfere with the browser and how
                    it is opened or closed. Typical problems include crash handler dialogs.
                </para>

                <para>
                    On Windows, disable error reporting in case a browser crashes as follows:
                </para>

                <orderedlist>
                    <listitem>
                        <para>
                            Open <menuchoice><guimenu>Control Panel</guimenu><guimenuitem>System</guimenuitem></menuchoice>
                        </para>
                    </listitem>
                    <listitem>
                        <para>
                            Select the <guilabel>Advanced</guilabel> tab
                        </para>
                    </listitem>
                    <listitem>
                    <para>
                            Select <guilabel>Error reporting</guilabel>
                        </para>
                    </listitem>
                    <listitem>
                        <para>
                            Check that <guilabel>Disable error reporting</guilabel> is selected
                        </para>
                    </listitem>
                    <listitem>
                        <para>
                            Check that <guilabel>But notify me when critical errors occur</guilabel> is not selected
                        </para>
                    </listitem>
                </orderedlist>
            </section>

            <section xml:id="testbench.installation.testnode.screenshot-settings">
                <title>Settings for Screenshots</title>

                <para>
                    The screenshot comparison feature requires that the user interface of
                    the browser stays constant. The exact features that interfere with
                    testing depend on the browser and the operating system.
                </para>

                <para>
                    In general:
                </para>

                <itemizedlist>
                    <listitem>
                        <para>
                            Disable blinking cursor
                        </para>
                    </listitem>
                    <listitem>
                        <para>
                            Use identical operating system themeing on every host
                        </para>
                    </listitem>
                    <listitem>
                        <para>
                            Turn off any software that may suddenly pop up a new window
                        </para>
                    </listitem>
                    <listitem>
                        <para>
                            Turn off screen saver
                        </para>
                    </listitem>
                </itemizedlist>
                
                <para>
                    If using Windows and Internet Explorer, you should give also the
                    following setting:
                </para>
                
                <itemizedlist>
                    <listitem>
                        <para>
                            Turn on <guilabel>Allow active content to run in files on My
                            Computer</guilabel> under <guilabel>Security
                            settings</guilabel>
                        </para>
                    </listitem>
                </itemizedlist>
            </section>
        </section>
    </section>

    <section xml:id="testbench.preparing">
        <title>Preparing an Application for Testing</title>

        <para>
            TestBench can usually be used for testing Vaadin applications as they are,
            especially if just taking screenshots.
        </para>

        <para>
            Depending on the selector type that you use later to select HTML elements,
            they can be vulnerable to logically irrelevant changes in the HTML DOM or
            component structure. The structure may change because of your layout or UI
            logic, or if a new Vaadin version has significant changes.
        </para>

        <para>
            To make UIs more robust for testing, you can set a unique <emphasis>component
            ID</emphasis> for specific components with
            <methodname>setId()</methodname>. You can then use it in Vaadin, XPath, or ID
            selectors, as explained later in <xref
            linkend="testbench.recorder.selectors"/>.
        </para>

        <programlisting><?pocket-size 65% ?><![CDATA[public class UIToBeTested extends UI {
    @Override
    protected void init(VaadinRequest request) {
        final VerticalLayout content = new VerticalLayout();
        setContent(content);
        
        // Create a button
        Button button = new Button("Push Me!");
        
        // Optional: give the button a unique ID
        button.setId("main.button");
        
        // Set the tooltip
        button.setDescription("This is a tip");

        // Do something when the button is clicked
        button.addClickListener(new ClickListener() {
            @Override
            public void buttonClick(ClickEvent event) {
                // This label will not have a set ID
                content.addComponent(new Label("Thanks!"));
            }
        });
        content.addComponent(button);
    }
}]]></programlisting>

        <para>
            The application is shown in <xref
            linkend="figure.testbench.preparing.application-to-be-tested"/>, with the
            button already clicked.
        </para>

        <figure xml:id="figure.testbench.preparing.application-to-be-tested">
            <title>A Simple Application To Be Tested</title>
            <mediaobject>
                <imageobject role="html">
                    <imagedata align="center" fileref="img/testbench/screenshots/application-to-be-tested.png"/>
                </imageobject>
                <imageobject role="fo">
                    <imagedata scale="120" smallscale="100%" align="center" fileref="img/testbench/screenshots/application-to-be-tested.png"/>
                </imageobject>
            </mediaobject>
        </figure>

        <para>
            The button would be rendered as a HTML element: <literal>&lt;div
            id="main.button" ...&gt;...&lt;/div&gt;</literal>. The DOM element would then
            be accessible from the HTML page with a WebDriver call such as:
            <literal>driver.findElement(By.id="main.button")</literal>. For the label,
            which does not have an ID, the path would be from the page root. A recorded
            test case stub for the above application is given in <xref
            linkend="testbench.development.stub"/>, which is further refined in this
            chapter.
        </para>

        <para>
            As a similar method, you can add a unique CSS class name for a component to
            enable using the CSS selector to select it. You can use the CSS class names
            and IDs also in XPath selectors.
        </para>

        <!-- TODO: A description of different selectors would be needed (XPath, CSS, ...) -->
    </section>

    <section xml:id="testbench.recorder">
        <title>Using Vaadin TestBench Recorder</title>

        <para>
            The Vaadin TestBench Recorder is used for recording and exporting JUnit test
            stubs that you can then develop further.
        </para>

        <para>
            The most important role for using the Recorder is to identify all user
            interface elements that you want to test - you can do all other test logic by
            coding. The elements are identified by a <emphasis>selector</emphasis> (or
            locator), which selects an element on which tests are made. By default, the
            Recorder records the paths using a <emphasis>Vaadin selector</emphasis>, where
            the root of the path is the UI element and the path consists of widgets. The
            path can also be an XPath or a CSS selector. It can use an ID that you set for
            a component in the application code.
        </para>

        <para>
            You can play back recoded test cases and use the Recorder to make assertions
            and take screenshots for screen capture comparison. Then, you export the test
            stubs as JUnit Java source files which you can then develop further.
        </para>
        
		<figure xml:id="figure.testbench.recorder.workflow">
			<title>Recorder Workflow</title>
			<mediaobject>
				<imageobject role="html">
					<imagedata align="center" fileref="img/testbench/tt-recorder-workflow-lo.png"/>
				</imageobject>
				<imageobject role="fo">
					<imagedata scale="120" smallscale="90%" align="center" fileref="img/testbench/tt-recorder-workflow-hi.png"/>
				</imageobject>
			</mediaobject>
		</figure>

        <para>
            The Recorder is available only for Mozilla Firefox. To run the recorded tests
            in other browsers, you need to export them as JUnit tests and launch the other
            browsers with the WebDriver, as described later.
        </para>

        <section xml:id="testbench.recorder.starting">
            <title>Starting the Recorder</title>

            <para>
                To start the Recorder:
            </para>

            <orderedlist>
                <listitem>
                    <para>Open Mozilla Firefox</para>
                </listitem>
                <listitem>
                    <para>Open the page with the application that you want to test</para>
                </listitem>
                <listitem>
                    <para>Select <menuchoice><guimenu>Tools</guimenu><guimenuitem>Vaadin
                    TestBench Recorder</guimenuitem></menuchoice> in the Firefox
                    menu</para>
        
                    <figure xml:id="figure.testbench.recorder.open">
                    <title>Starting Vaadin TestBench Recorder</title>
                        <mediaobject>
                            <imageobject role="html">
                                <imagedata align="center" fileref="img/testbench/screenshots/tt-recorder-open.png"/>
                            </imageobject>
                            <imageobject role="fo">
                                <imagedata scale="80" smallscale="80%" align="center" fileref="img/testbench/screenshots/tt-recorder-open.png"/>
                            </imageobject>
                        </mediaobject>
                    </figure>
                </listitem>
            </orderedlist>
            
            <para>
                The Vaadin TestBench Recorder window will open, as shown in <xref
                linkend="figure.testbench.recorder.recording-1"/>.
            </para>

            <figure xml:id="figure.testbench.recorder.recording-1">
                <title>Vaadin TestBench Recorder Running</title>
                <mediaobject>
                    <imageobject role="html">
                        <imagedata align="center" fileref="img/testbench/screenshots/recorder-recording-1.png"/>
                    </imageobject>
                    <imageobject role="fo">
                        <imagedata scale="80" smallscale="100%" align="center" fileref="img/testbench/screenshots/recorder-recording-1.png"/>
                    </imageobject>
                </mediaobject>
            </figure>

            <para>
                Recording is automatically enabled when the Recorder starts. This is
                indicated by the pressed <inlinegraphic
                fileref="img/testbench/inline/inline-record-button.png"/>
                <guibutton>Record</guibutton> button.
            </para>
        </section>

        <section xml:id="testbench.recorder.recording">
            <title>Recording</title>

            <para>
                While recording, you can interact with the application in (almost) any way
                you like. The Recorder records the interaction as commands in a test
                script, which is shown in tabular format in the Table tab and as HTML
                source code in the Source tab.
            </para>

            <figure xml:id="figure.testbench.recorder.recording">
                <title>User Interaction Recorded as Commands</title>
                <mediaobject>
                    <imageobject role="html">
                        <imagedata align="center" fileref="img/testbench/screenshots/recorder-recording-2.png"/>
                    </imageobject>
                    <imageobject role="fo">
                        <imagedata scale="80" smallscale="100%" align="center" fileref="img/testbench/screenshots/recorder-recording-2.png"/>
                    </imageobject>
                </mediaobject>
            </figure>

            <para>
                Please note the following:
            </para>

            <itemizedlist>
                <listitem>
                    <para>
                        Changing browser tabs or opening a new browser window is not
                        recommended, as any clicks and other actions will be recorded
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Passwords are considered to be normal text input and are stored in
                        plain text
                    </para>
                </listitem>
            </itemizedlist>

            <para>
                While recording, you can insert various commands, such as assertions, by
                selecting the command from the Command list. You can also right-click on
                an element in your UI and select an assertion command. Doing so will
                automatically fill the asserted value in Recorder.
            </para>

            <para>
                When you are finished, click the <inlinegraphic
                fileref="img/testbench/inline/inline-record-button.png"/>
                <guibutton>Record</guibutton> button to stop recording.
            </para>
        </section>

        <section xml:id="testbench.recorder.selectors">
            <title>Selectors</title>

            <para>
                The Recorder supports various <emphasis>selectors</emphasis> (or locators)
                to find the HTML elements that are interacted upon and asserted. By
                default, Recorder uses the <emphasis>Vaadin selector</emphasis>, which
                finds the elements by a UI identifier, a possible component ID, and a
                widget hierarchy path.
            </para>

            <para>
                You can find elements also by a plain XPath expression, an
                element ID, CSS style class, etc. The selectors are exported with the
                JUnit test cases as corresponding Vaadin or Selenium selector methods,
                described in <xref linkend="testbench.development.selectors"/>.
            </para>

            <para>
                Some selectors are not applicable to all elements, for example if an
                element does not have an ID or it is outside the Vaadin application. In
                such case, another selector is used according to a preference order. You
                can change the order of the preferred selectors by selecting
                <menuchoice><guimenu>Options</guimenu><guisubmenu>Options</guisubmenu><guimenuitem>Locator
                Builders</guimenuitem></menuchoice> and dragging the selectors (or
                locators) to a preferred order. Normally, the Vaadin selector should be at
                top of the list.
            </para>

            <section xml:id="testbench.recorder.selectors.robustness">
                <title>Selector Robustness</title>

                <para>
                    As mentioned in <xref linkend="testbench.preparing"/>, the selectors
                    have differences in their robustness, which is important to avoid
                    failed tests if there are irrelevant changes in the HTML DOM tree.
                </para>

                <para>
                    The Vaadin selector (<literal>vaadin</literal> in Recorder and
                    <methodname>By.vaadin()</methodname> in WebDriver) uses the logical
                    widget hierarchy to find the HTML element to test, instead of the
                    exact DOM structure. This makes it rather robust, though still
                    vulnerable to irrelevant changes in the exact component hierarchy.
                </para>

                <para>
                    The XPath selector can be highly vulnerable to changes in the DOM path
                    if the path is given exactly from the body element of the page. It is,
                    however, very flexible, and can be used in robust ways, for example,
                    by selecting by HTML element and a CSS class name or an attribute
                    value.
                </para>

                <para>
                    You can likewise use a CSS selector to select specific components by
                    CSS class in a robust way.
                </para>
            </section>
        </section>

        <section xml:id="testbench.recorder.playback">
            <title>Playing Back Tests</title>

            <para>
                After you have stopped recording, reset the application to the initial
                state and press <inlinegraphic
                fileref="img/testbench/inline/inline-play-button.png"/> <guibutton>Play
                current test</guibutton> to run the test again. You can use the
                <literal>?restartApplication</literal> parameter for an application in
                the URL to restart it.
            </para>

            <para>
                You can also play back tests saved in the HTML format by first opening a
                test in the Recorder with
                <menuchoice><guimenu>File</guimenu><guimenuitem>Open</guimenuitem></menuchoice>.
            </para>

            <para>
                You can use the <inlinegraphic
                fileref="img/testbench/inline/inline-slider-fastslow.png"/> slider to
                control the playback speed, click <guibutton>Pause</guibutton> to
                interrupt the execution and <guibutton>Resume</guibutton> to
                continue. While paused, you can click <guibutton>Step</guibutton> to
                execute the script step-by-step.
            </para>

            <para>
                Check that the test works as intended and no unintended or invalid commands are
                found; a test should run without errors.
            </para>
        </section>

        <section xml:id="testbench.recorder.editing">
            <title>Editing Tests</title>

            <para>
                While the primary purpose of using the Recorder is to identify all user
                interface elements to be tested, you can also edit the tests at this
                point. You can insert various commands, such as assertions or taking a
                screenshot, in the test script during or after recording.
            </para>

            <para>
                You insert a command by selecting an insertion point in the test script
                and right-clicking an element in the browser. A context menu opens and
                shows a selection of Recorder commands at the bottom. Selecting
                <guimenuitem>Show All Available Commands</guimenuitem> shows more
                commands. Commands inserted from the sub-menu are automatically added to
                the top-level context menu.
            </para>

            <para>
                <xref linkend="figure.testbench.recorder.inserting"/> shows adding an
                assertion after clicking the button in the example application.
            </para>

            <figure xml:id="figure.testbench.recorder.inserting">
                <title>Inserting commands in a test script</title>
                <mediaobject>
                    <imageobject role="html">
                        <imagedata align="center" fileref="img/testbench/screenshots/tt-recorder-inserting.png"/>
                    </imageobject>
                    <imageobject role="fo">
                        <imagedata scale="120" smallscale="75%" align="center" fileref="img/testbench/screenshots/tt-recorder-inserting.png"/>
                    </imageobject>
                </mediaobject>
            </figure>

            <para>
                Inserting a command from the context menu automatically selects the
                command in the <guilabel>Command</guilabel> field and fills in the target
                and value parameters.
            </para>

            <para>
                You can also select the command manually from the
                <guilabel>Command</guilabel> list. The new command or comment will be
                added at the selected location, moving the selected location down. If the
                command requires a target element, click <guilabel>Select</guilabel> and
                then click an element in your application. A reference to the element is
                shown in the <guilabel>Target</guilabel> field and you can highlight the
                element by clicking <guilabel>Show</guilabel>. If the command expects some
                value, such as for comparing the element value, give it in the
                <guilabel>Value</guilabel> field.
            </para>

            <para>
                Commands in a test script can be changed by selecting a command and
                changing the command, target, or value.
            </para>
        </section>

        <section xml:id="testbench.recorder.exporting">
            <title>Exporting Tests</title>

            <para>
                Once you are satisfied with a test case, you need to export it as a
                JUnit test case stub.
            </para>

            <para>
                You can save a test by selecting
                <menuchoice><guimenu>File</guimenu><guisubmenu>Export Test Case
                As...</guisubmenu><guimenuitem>JUnit 4 (Vaadin
                TestBench)</guimenuitem></menuchoice>.
            </para>

            <figure xml:id="figure.testbench.recorder.exporting">
                <title>Exporting Test Case as JUnit Test</title>
                <mediaobject>
                    <imageobject role="html">
                        <imagedata align="center" fileref="img/testbench/recorder-export-testcase-lo.png"/>
                    </imageobject>
                    <imageobject role="fo">
                        <imagedata scale="80" smallscale="80%" align="center" fileref="img/testbench/recorder-export-testcase-hi.png"/>
                    </imageobject>
                </mediaobject>
            </figure>

            <para>
                In the dialog that opens, enter a file name for the Java source file. The
                file contains a Java class with name <classname>Testcase</classname>, so
                you might want to name the file as <filename>Testcase.java</filename>. You
                can rename the class later.
            </para>
        </section>

        <section xml:id="testbench.recorder.saving">
            <title>Saving Tests</title>

            <para>
                While exporting tests as JUnit tests is the normal case, the Recorder also
                allows saving test cases and test suites in a HTML format that can be
                loaded back in the Recorder. Vaadin TestBench does not support other use
                for these saved tests, but you may still find the feature useful if you
                like to develop test cases more with the Recorder.
            </para>
        </section>
    </section>

    <section xml:id="testbench.development">
        <title>Developing JUnit Tests</title>

        <para>
            Tests are developed using the Selenium WebDriver, which is augmented with
            Vaadin TestBench API features useful for testing Vaadin applications.
        </para>

        <para>
            Perhaps the easiest way to start developing tests is to use the Recorder to
            create a JUnit test stub, which is described in the next section.  The main
            purpose of the recorder is to help identify the HTML DOM paths of the user
            interface elements that you want to interact with and use for assertions. Once
            you get the hang of coding tests, you should be able to do it without using
            the Recorder. Working with component IDs and using a browser debugger, such as
            Firebug, is usually the easiest way to find out the DOM paths. You can also
            use the Recorder just to find the paths, and copy and paste them directly to
            your source code without going through the export hassle.
        </para>

        <para>
            While this section describes the development of JUnit tests, Vaadin TestBench
            and the WebDriver are in no way specific to JUnit and you can use any test
            execution framework, or just regular Java applications, to develop TestBench
            tests.
        </para>

        <section xml:id="testbench.development.stub">
            <title>Starting From a Stub</title>

            <para>
                Let us assume that you recorded a simple application, as described
                earlier, and exported it as a JUnit stub. You can add it to a project in a
                suitable package. You may want to keep your test classes in a separate
                source tree in your application project, or in an altogether separate
                project, so that you do not have to include them in the web application
                WAR. Having them in the same project may be nicer for version control
                purposes.
            </para>

            <para>
                You need to perform at least the following routine tasks:
            </para>

            <itemizedlist>
                <listitem>Rename the package</listitem>
                <listitem>Rename the class</listitem>
                <listitem>Organize imports</listitem>
                <listitem>Check the base URL</listitem>
                <listitem>Clean up unnecessary code</listitem>
            </itemizedlist>

            <para>
                A JUnit stub will look somewhat as follows:
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[package com.example.tests;

import org.junit.*;
import static org.junit.Assert.*;
...
import com.vaadin.testbench.By;
import com.vaadin.testbench.TestBench;
import com.vaadin.testbench.TestBenchTestCase;
import com.vaadin.testbench.ScreenshotOnFailureRule;

public class Testcase extends TestBenchTestCase {
	private String baseUrl;
	private StringBuffer verificationErrors = new StringBuffer();
    ...]]></programlisting>

            <para>
                The <parameter>verificationErrors</parameter> is used to collect some
                errors in some recorded commands, but can be removed if such commands are
                not used. You can also use it to collect non-fatal errors, for example
                screenshot comparison errors, and only fail on logic errors.
            </para>

            <simplesect xml:id="testbench.development.stub.setup">
                <title>Test Setup</title>

                <para>
                    The set-up method, annotated with <literal>@Before</literal>, makes
                    the basic configuration for the test. Most importantly, it creates the
                    <classname>WebDriver</classname> instance, which is for Firefox by
                    default. Drivers for different browsers extend the
                    <classname>RemoteWebDriver</classname> class - see the API type
                    hierarchy for the complete list.
                </para>

                <programlisting><?pocket-size 65% ?><![CDATA[    @Before
    public void setUp() throws Exception {
        setDriver(TestBench.createDriver(new FirefoxDriver()));
        baseUrl = "http://localhost:8080/myapp";
    }]]></programlisting>

                <para>
                    Check that the <parameter>baseUrl</parameter> is the correct URL for
                    the application. It might not be.
                </para>
            </simplesect>

            <simplesect xml:id="testbench.development.stub.testcase">
                <title>Test Case Stub</title>
                
                <para>
                    The test case methods are marked with <literal>@Test</literal>
                    annotation. They normally start by calling the
                    <methodname>get()</methodname> method in the driver. This loads the
                    URL in the browser.
                </para>

                <para>
                    Actual test commands usually call the
                    <methodname>findElement()</methodname> method in the driver to get
                    hold of an HTML element to work with. The button has the
                    <literal>main.button</literal> ID, as we set that ID for the
                    <classname>Button</classname> object with the
                    <methodname>setId()</methodname> method in the application. The
                    HTML element is represented as a <classname>WebElement</classname>
                    object.
                </para>

                <programlisting><?pocket-size 65% ?><![CDATA[@Test
public void testCase() throws Exception {
    driver.get(concatUrl(baseUrl, "/myapp"));

    // Check the button caption
    assertEquals("Push Me!", driver.findElement(By.vaadin(
        "bookexamplestobetested::PID_Smain.button")).getText());

    // Click the button
    driver.findElement(By.vaadin(
        "bookexamplestobetested::PID_Smain.button")).click();

    // Check the result
    assertEquals("Thanks!", driver.findElement(By.vaadin(
        "bookexamplestobetested::/VVerticalLayout[0]/"+
        "ChildComponentContainer[1]/VLabel[0]")).getText());
}]]></programlisting>

                <para>
                    The <methodname>get()</methodname> call appends the application path
                    to the base URL. If it is already included in the base URL, you can
                    remove it.
                </para>
            </simplesect>

            <simplesect xml:id="testbench.development.stub.other">
                <title>After Testing</title>

                <para>
                    Finally after running all the test cases, the method annotated with
                    <literal>@After</literal> is called. Calling
                    <methodname>quit()</methodname> for the driver closes the browser
                    window.
                </para>

                <para>
                    The stub includes code for collecting verification errors. If you do
                    not collect those, as is often the case, you can remove the code.
                </para>

                <programlisting><?pocket-size 65% ?><![CDATA[    @After
    public void tearDown() throws Exception {
        driver.quit();

        String verificationErrorString =
            verificationErrors.toString();
        if (!"".equals(verificationErrorString)) {
            fail(verificationErrorString);
        }
    }]]></programlisting>
            </simplesect>
        </section>

        <section xml:id="testbench.development.selectors">
            <title>Finding Elements by Selectors</title>

            <para>
                The Selenium WebDriver API provides a number of different
                <emphasis>selectors</emphasis> for finding HTML DOM elements. The
                available selectors are defined as static methods in the
                <classname>com.vaadin.testbench.By</classname> class. They create and
                return a <classname>By</classname> instance, which you can use for the
                <methodname>findElement()</methodname> method in
                <classname>WebDriver</classname>.
            </para>

            <para>
                The ID, CSS class, and Vaadin selectors are described below. For others,
                we refer to the <link
                xlink:href="http://seleniumhq.org/docs/03_webdriver.html">Selenium
                WebDriver API documentation</link>.
            </para>

            <section xml:id="testbench.development.selectors.id">
                <title>Finding by ID</title>

                <para>
                    Selecting elements by their HTML element <literal>id</literal>
                    attribute is usually the easiest way to select elements. It requires
                    that you use component IDs, as described in <xref
                    linkend="testbench.preparing"/>. The ID is used as is for the
                    <literal>id</literal> attribute of the top element of the
                    component. Selecting is done by the <methodname>By.id()</methodname>
                    selector.
                </para>

                <para>
                    For example, in the <filename>SimpleCalculatorITCase.java</filename>
                    example, we use the component ID as follows to click on the calculator
                    buttons:
                </para>

        <programlisting><?pocket-size 75% ?><![CDATA[@Test
public void testOnePlusTwo() throws Exception {
    openCalculator();

    // Click the buttons in the user interface
    getDriver().findElement(By.id("button_1")).click();
    getDriver().findElement(By.id("button_+")).click();
    getDriver().findElement(By.id("button_2")).click();
    getDriver().findElement(By.id("button_=")).click();

    // Get the result label value
    assertEquals("3.0", getDriver().findElement(
            By.id("display")).getText());
}]]></programlisting>

                <para>
                    The ID selectors are used extensively in the TestBench examples.
                </para>
            </section>

            <section xml:id="testbench.development.selectors.vaadin">
                <title>Finding by Vaadin Selector</title>

                <para>
                    In addition to the Selenium selectors, Vaadin TestBench provides a
                    <emphasis>Vaadin selector</emphasis>, which allows pointing to a
                    Vaadin component by its layout path.  The JUnit test cases saved from
                    the Recorder use Vaadin selectors by default.
                </para>

                <para>
                    You can create a Vaadin selector with the
                    <methodname>By.vaadin()</methodname> method. You need to use the
                    Vaadin <classname>By</classname>, defined in the
                    <package>com.vaadin.testbench</package> package, which extends the
                    Selenium <classname>By</classname>.
                </para>

                <para>
                    The other way is to use the
                    <methodname>findElementByVaadinSelector()</methodname> method in the
                    <interfacename>TestBenchCommands</interfacename> interface. It returns
                    the <classname>WebElement</classname> object.
                </para>

                <para>
                    A Vaadin selector begins with an application identifier. It is the
                    path to application without any slashes or other special
                    characters. For example, <literal>/book-examples/tobetested</literal>
                    would be <literal>bookexamplestobetested</literal>. After the
                    identifier, comes two colons "<literal>::</literal>", followed by a
                    slash-delimited component path to the component to be selected. The
                    elements in the component path are client-side classes of the Vaadin
                    user interfacer components. For example, the server-side
                    <classname>VerticalLayout</classname> component has
                    <classname>VVerticalLayout</classname> client-side counterpart. All
                    path elements except the leaves are component containers, usually
                    layouts. The exact contained component is identified by its index in
                    brackets.
                </para>

                <para>
                    A reference to a component ID is given with a <literal>PID_S</literal>
                    suffix to the ID.
                </para>

                <para>
                    For example, if the ID is <literal>main.button</literal>, as it was
                    set in the application example earlier, you could find and test it as
                    follows:
                </para>

        <programlisting><?pocket-size 75% ?><![CDATA[// Get the button's element.
// Use the ID set with setId().
WebElement button = driver.findElement(By.vaadin(
    "bookexamplestobetested::PID_Smain.button"));

// Get the caption text
assertEquals("Push Me!", button.getText());

// And click it
button.click();

// Get the Label's element by full path
WebElement label = driver.findElement(By.vaadin(
    "bookexamplestobetested::/VVerticalLayout[0]/"+
    "ChildComponentContainer[1]/VLabel[0]"));

// Make the assertion
assertEquals("Thanks!", label.getText());]]></programlisting>

            </section>

            <section xml:id="testbench.development.selectors.css">
                <title>Finding by CSS Class</title>

                <para>
                    An element with a particular CSS style class name can be selected with
                    the <methodname>By.className()</methodname> method. CSS selectors are
                    useful for elements which have no ID, nor can be found easily from the
                    component hierarchy, but do have a particular unique CSS
                    style. Tooltips are one example, as they are floating
                    <literal>div</literal> elements under the root element of the
                    application. Their <literal>v-tooltip</literal> style makes it
                    possible to select them as follows:
                </para>

                <programlisting><?pocket-size 75% ?><![CDATA[// Verify that the tooltip contains the expected text
String tooltipText = driver.findElement(
    By.className("v-tooltip")).getText();]]></programlisting>

                <para>
                    For a complete example, see the
                    <filename>AdvancedCommandsITCase.java</filename> file in the examples.
                </para>
            </section>
        </section>

        <section xml:id="testbench.development.eclipse">
            <title>Running JUnit Tests in Eclipse</title>

            <para>
                The Eclipse IDE integrates JUnit with nice control features. To run
                TestBench JUnit test cases in Eclipse, you need to do the following:
            </para>

            <orderedlist>
                <listitem>
                    Add the TestBench JAR to a library folder in the project, such as
                    <filename>lib</filename>. You should not put the library in
                    <filename>WEB-INF/lib</filename> as it is not used by the Vaadin web
                    application. Refresh the project by selecting it and pressing
                    <keycap>F5</keycap>.
                </listitem>
                <listitem>
                    Right-click the project in Project Explorer and select
                    <guilabel>Properties</guilabel>, and open the <guilabel>Java Build
                    Path</guilabel> and the <guilabel>Libraries</guilabel> tab. Click
                    <guibutton>Add JARs</guibutton>, navigate to the library folder,
                    select the library, and click <guibutton>OK</guibutton>.
                </listitem>
                <listitem>
                    Switch to the <guilabel>Order and Export</guilabel> tab in the project
                    properties. Make sure that the TestBench JAR is above the
                    <filename>gwt-dev.jar</filename> (it may contain an old
                    <filename>httpclient</filename> package), by selecting it and moving
                    it with the <guibutton>Up</guibutton> and <guibutton>Down</guibutton>
                    buttons.
                </listitem>
                <listitem>
                    Click <guibutton>OK</guibutton> to exit the project properties.
                </listitem>
                <listitem>
                    Right-click a test source file and select <menuchoice><guimenu>Run
                    As</guimenu><guimenuitem>JUnit Test</guimenuitem></menuchoice>.
                </listitem>
            </orderedlist>

            <para>
                A JUnit view should appear, and it should open the Firefox browser, launch
                the application, run the test, and then close the browser window. If all
                goes well, you have a passed test case, which is reported in the JUnit
                view area in Eclipse, as illustrated in <xref
                linkend="figure.testbench.development.eclipse"/>.
            </para>

            <figure xml:id="figure.testbench.development.eclipse">
                <title>Running JUnit Tests in Eclipse</title>
                <mediaobject>
                    <imageobject>
                        <imagedata scale="85" smallscale="100%" align="center" fileref="img/testbench/screenshots/eclipse-junit-run.png"/>
                    </imageobject>
                </mediaobject>
            </figure>

            <para>
                If you are using some other IDE, it might support JUnit tests as well. If
                not, you can run the tests using Ant or Maven.
            </para>
        </section>

        <section xml:id="testbench.development.ant">
            <title>Executing Tests with Ant</title>

            <para>
                Apache Ant has built-in support for executing JUnit tests. To enable the
                support, you need to have the JUnit library <filename>junit.jar</filename>
                and its Ant integration library <filename>ant-junit.jar</filename> in the
                Ant classpath, as described in the Ant documentation.
            </para>

            <para>
                Once enabled, you can use the <literal>&lt;junit&gt;</literal> task in an
                Ant script. The following example assumes that the source files are
                located under a <filename>src</filename> directory under the current
                directory and compiles them to the <filename>classes</filename>
                directory. The the class path is defined with the
                <literal>classpath</literal> reference ID and should include the TestBench
                JAR and all relevant dependencies.
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[<project default="run-tests">
    <path id="classpath">
        <fileset dir="lib"
                 includes="vaadin-testbench-standalone-*.jar" />
    </path>

    <!-- This target compiles the JUnit tests. -->
    <target name="compile-tests">
        <mkdir dir="classes" />
        <javac srcdir="src" destdir="classes"
               debug="on" encoding="utf-8">
            <classpath>
                <path refid="classpath" />
            </classpath>
        </javac>
    </target>

    <!-- This target calls JUnit -->
    <target name="run-tests" depends="compile-tests">
        <junit fork="yes">
            <classpath>
                <path refid="classpath" />
                <pathelement path="classes" />
            </classpath>

            <formatter type="brief" usefile="false" />
                                
            <batchtest>
                <fileset dir="src">
                    <include name="**/**.java" />
                </fileset>
            </batchtest>
        </junit>
    </target>
</project>]]></programlisting>

            <para>
                You also need to deploy the application to test, and possibly launch a
                dedicated server for it.
            </para>
        </section>

        <section xml:id="testbench.development.maven">
            <title>Executing Tests with Maven</title>

            <para>
                Executing JUnit tests with Vaadin TestBench under Maven requires
                installing the TestBench library in the local Maven repository and
                defining it as a dependency in any POM that needs to execute TestBench
                tests.
            </para>

            <para>
                A complete example of a Maven test setup is given in the
                <filename>example/maven</filename> folder in the installation
                package. Please see the <filename>README</filename> file in the folder for
                further instructions.
            </para>

            <section xml:id="testbench.development.maven.install">
                <title>Installing TestBench in Local Repository</title>

                <para>
                    You can install TestBench in the local Maven repository with the following
                    commands:
                </para>

                <screen><prompt>$</prompt> <command>cd</command> <parameter>maven</parameter>
<prompt>$</prompt> <command>mvn</command> install:install-file \
   -Dfile=<parameter>vaadin-testbench-&version.testbench;-SNAPSHOT.jar</parameter> \
   -DpomFile=<parameter>pom.xml</parameter></screen>

                <para>
                    The <filename>maven</filename> folder also includes an
                    <filename>INSTALL</filename> file, which contains instructions for
                    installing TestBench in Maven.
                </para>

            </section>

            <section xml:id="testbench.development.maven.dependency">
                <title>Defining TestBench as a Dependency</title>

                <para>
                    Once TestBench is installed in the local repository as instructed in
                    the previous section, you can define it as a dependency in the Maven
                    POM of your project as follows:
                </para>

                <programlisting><?pocket-size 65% ?><![CDATA[    &lt;dependency&gt;
      &lt;groupId&gt;com.vaadin&lt;/groupId&gt;
      &lt;artifactId&gt;vaadin-testbench&lt;/artifactId&gt;
      &lt;version&gt;&version.testbench;-SNAPSHOT&lt;/version&gt;
    &lt;/dependency&gt;]]></programlisting>

                <para>
                    For instructions on how to create a new Vaadin project with Maven,
                    please see <xref linkend="getting-started.maven"/>.
                </para>
            </section>

            <section xml:id="testbench.development.maven.running">
                <title>Running the Tests</title>

                <para>
                    To compile and run the tests, simply execute the
                    <literal>test</literal> lifecycle phase with Maven as follows:
                </para>

                <screen><prompt>$</prompt> <command>mvn</command> test
...
-----------------------------------------------------
 T E S T S
-----------------------------------------------------
Running TestBenchExample
Tests run: 6, Failures: 2, Errors: 0, Skipped: 1, Time elapsed: 36.736 sec &lt;&lt;&lt; FAILURE!

Results :

Failed tests: 
  testDemo(TestBenchExample):
      expected:&lt;[5/17/]12&gt; but was:&lt;[17.6.20]12&gt;
  testScreenshot(TestBenchExample): Screenshots differ

Tests run: 6, Failures: 2, Errors: 0, Skipped: 1
...</screen>

                <para>
                    The example configuration starts Jetty to run the application that is
                    tested. Error screenshots from screenshot comparison are written to
                    the <filename>target/testbench/errors</filename> folder. To enable
                    comparing them to "expected" screenshots, you need to copy the
                    screenshots to the
                    <filename>src/test/resources/screenshots/reference/</filename>
                    folder. See <xref linkend="testbench.screenshots"/> for more
                    information regarding screenshots.
                </para>
            </section>
        </section>

        <section xml:id="testbench.development.setup">
            <title>Test Setup</title>

            <para>
                Test configuration is done in a method annotated with
                <literal>@Before</literal>. The method is executed before each test
                case. In a JUnit stub exported from Recorder, this is done in the
                <methodname>setUp()</methodname> method.
            </para>

            <para>
                The basic configuration tasks are:
            </para>

            <itemizedlist>
                <listitem>Set TestBench parameters</listitem>
                <listitem>Create the web driver</listitem>
                <listitem>Do any other initialization</listitem>
            </itemizedlist>

            <section xml:id="testbench.development.setup.parameters">
                <title>TestBench Parameters</title>

                <para>
                    TestBench parameters are defined with static methods in the
                    <classname>com.vaadin.testbench.Parameters</classname> class. The
                    parameters are mainly for screenshots and documented in <xref
                    linkend="testbench.screenshots"/>.
                </para>
            </section>
        </section>

        <section xml:id="testbench.development.webdriver">
            <title>Creating and Closing a Web Driver</title>
            
            <para>
                Vaadin TestBench uses Selenium WebDriver to execute tests in a
                browser. The <classname>WebDriver</classname> instance is created with the
                static <methodname>createDriver()</methodname> method in the
                <classname>TestBench</classname> class. It takes the driver as the
                parameter and returns it after registering it. The test cases must extend
                the <classname>TestBenchTestCase</classname> class, which manages the
                TestBench-specific features.
            </para>

            <para>
                The basic way is to create the driver in a method annotated with the
                JUnit <literal>@Before</literal> annotation and close it in a method
                annotated with <literal>@After</literal>.
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[public class AdvancedTest extends TestBenchTestCase {
    private WebDriver driver;

    @Before
    public void setUp() throws Exception {
        ...
        driver = TestBench.createDriver(new FirefoxDriver());
    }
    ...
    @After
    public void tearDown() throws Exception {
        driver.quit();
    }
}]]></programlisting>

            <para>
                This creates the driver for each test you have in the test class, causing
                a new browser instance to be opened and closed. If you want to keep the
                browser open between the test, you can use <literal>@BeforeClass</literal>
                and <literal>@AfterClass</literal> methods to create and quit the
                driver. In that case, the methods as well as the driver instance have to
                be static.
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[public class AdvancedTest extends TestBenchTestCase {
    static private WebDriver driver;

    @BeforeClass
    static public void createDriver() throws Exception {
        driver = TestBench.createDriver(new FirefoxDriver());
    }
    ...
    @AfterClass
    static public void tearDown() throws Exception {
        driver.quit();
    }
}]]></programlisting>

            <section xml:id="testbench.development.webdriver.browsers">
                <title>Browser Drivers</title>

                <para>
                    Please see the API documentation of the
                    <interfacename>WebDriver</interfacename> interface for a complete list
                    of supported drivers, that is, classes implementing the interface.
                </para>

                <para>
                    Both the Internet Explorer and Chrome require a special driver, as was
                    noted in <xref linkend="testbench.installation.browserdrivers"/>. The
                    driver executable must be included in the operating system
                    <literal>PATH</literal> or be given with a driver-specific system
                    property in Java with: <methodname>System.setProperty(prop,
                    key))</methodname>.
                </para>

                <itemizedlist>
                    <listitem>Chrome: <parameter>webdriver.chrome.driver</parameter></listitem>
                    <listitem>IE: <parameter>webdriver.ie.driver</parameter></listitem>
                </itemizedlist>

                <para>
                    If you use an ESR version of Firefox, which is recommended for test
                    stability, you need to the binary when creating the driver as follows:
                </para>

                <programlisting><?pocket-size 65% ?><![CDATA[FirefoxBinary binary =
    new FirefoxBinary(new File("/path/to/firefox_ESR_10"));
driver = TestBench.createDriver(
    new FirefoxDriver(binary, new FirefoxProfile()));]]></programlisting>
            </section>
        </section>

        <section xml:id="testbench.development.basic">
            <title>Basic Test Case Structure</title>

            <para>
                A typical test case does the following:
            </para>

            <orderedlist>
                <listitem>Open the URL</listitem>
                <listitem>Navigate to desired state
                    <orderedlist>
                        <listitem>Find a HTML element (<classname>WebElement</classname>) for navigation</listitem>
                        <listitem>Use <methodname>click()</methodname> and other commands to interact with the element</listitem>
                        <listitem>Repeat with different elements until desired state is reached</listitem>
                    </orderedlist>
                </listitem>
                <listitem>Find a HTML element (<classname>WebElement</classname>) to check</listitem>
                <listitem>Get and assert the value of the HTML element</listitem>
                <listitem>Get a screenshot</listitem>
            </orderedlist>

            <para>
                The <classname>WebDriver</classname> allows finding HTML elements in a
                page in various ways, for example, with XPath expressions. The access
                methods are defined statically in the <classname>By</classname> class.
            </para>

            <para>
                These tasks are realized in the following test code:
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[@Test
public void testCase1() throws Exception {
    driver.get(baseUrl + "/book-examples/tobetested");
    
    // Get the button's element.
    // (Actually the caption element inside the button.)
    // Use the component ID assigned with setId().
    WebElement button = driver.findElement(By.xpath(
        "//div[@id='main.button']/span/span"));
    
    // Get the caption text
    assertEquals("Push Me!", button.getText());
    
    // And click it. It's OK to click the caption element.
    button.click();
    
    // Get the Label's element.
    // Use the automatically generated ID.
    WebElement label = driver.findElement(By.xpath(
        "//div[@id='myapp-949693921']" +
        "/div/div[2]/div/div[2]/div/div"));

    // Make the assertion
    assertEquals("Thanks!", label.getText());
}]]></programlisting>

            <para>
                You can also use URI fragments in the URL to open the application at a
                specific state. <phrase condition="web">For information about URI fragments, see <xref
                linkend="advanced.urifu"/>.</phrase>
            </para>

            <para>
                You should use the JUnit assertion commands. They are static methods
                defined in the <package>org.junit.Assert</package> class, which you can
                import (for example) with:
            </para>

            <programlisting><![CDATA[import static org.junit.Assert.assertEquals;]]></programlisting>

            <para>
                Please see the <link
                xlink:href="http://seleniumhq.org/docs/03_webdriver.html#selenium-webdriver-api-commands-and-operations">Selenium
                API documentation</link> for a complete reference of the element search
                methods in the <classname>WebDriver</classname> and
                <classname>By</classname> classes and for the interaction commands in the
                <classname>WebElement</classname> class.
            </para>

            <para>
                TestBench has a collection of its own commands, defined in the
                <interfacename>TestBenchCommands</interfacename> interface. You can get a command
                object that you can use by calling <literal>testBench(driver)</literal> in
                a test case.
            </para>
        </section>

        <section xml:id="testbench.development.waitforvaadin">
            <title>Waiting for Vaadin</title>

            <para>
                Selenium is intended for regular web applications that load a page that is
                immediately rendered by the browser. Vaadin, on the other hand, is an Ajax
                framework where page is loaded just once and rendering is done in
                JavaScript. This takes more time so that the rendering might not be
                finished when the WebDriver continues executing the test. Vaadin TestBench
                allows waiting until the rendering is finished.
            </para>

            <para>
                The waiting is automatically enabled. You can disable waiting by calling
                <methodname>disableWaitForVaadin()</methodname> in the
                <interfacename>TestBenchCommands</interfacename> interface. You can call
                it in a test case as follows:
            </para>

            <programlisting><![CDATA[testBench(driver).disableWaitForVaadin();]]></programlisting>

            <para>
                When disabled, you can wait for the rendering to finish by calling
                <methodname>waitForVaadin()</methodname> explicitly.
            </para>

            <programlisting><![CDATA[testBench(driver).waitForVaadin();]]></programlisting>

            <para>
                You can re-enable the waiting with
                <methodname>enableWaitForVaadin()</methodname> in the same interface.
            </para>
        </section>

        <section xml:id="testbench.development.tooltip">
            <title>Testing Tooltips</title>

            <para>
                Component tooltips show when you hover the mouse over a component. Events
                caused by hovering are not recorded by Recorder, so this interaction
                requires special handling when testing.
            </para>

            <para>
                Let us assume that you have set the tooltip as follows:
            </para>

            <programlisting><![CDATA[// Create a button with a component ID
Button button = new Button("Push Me!");
button.setId("main.button");

// Set the tooltip        
button.setDescription("This is a tip");]]></programlisting>

            <para>
                The tooltip of a component is displayed with the
                <methodname>showTooltip()</methodname> method in the
                <classname>TestBenchElementCommands</classname> interface. You should wait
                a little to make sure it comes up. The floating tooltip element is not
                under the element of the component, but you can find it by
                <literal>//div[@class='v-tooltip']</literal> XPath expression.
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[@Test
public void testTooltip() throws Exception {
    driver.get(appUrl);
    
    // Get the button's element.
    // Use the component ID given with setId().
    WebElement button = driver.findElement(By.xpath(
        "//div[@id='main.button']/span/span"));
    
    // Show the tooltip
    testBenchElement(button).showTooltip();
    
    // Wait a little to make sure it's up
    Thread.sleep(1000);
    
    // Check that the tooltip text matches
    assertEquals("This is a tip", driver.findElement(
        By.xpath("//div[@class='v-tooltip']")).getText());
    
    // Compare a screenshot just to be sure
    assertTrue(testBench(driver).compareScreen("tooltip"));
}]]></programlisting>

        </section>

        <section xml:id="testbench.development.scrolling">
            <title>Scrolling</title>

            <para>
                Some Vaadin components, such as <classname>Table</classname> and
                <classname>Panel</classname> have a scrollbar. To get hold of the
                scrollbar, you must first find the component element. Then, you need to
                get hold of the <interfacename>TestBenchElementCommands</interfacename>
                interface from the <classname>WebElement</classname> with
                <methodname>testBenchElement(WebElement)</methodname>. The
                <methodname>scroll()</methodname> method in the interface scrolls a
                vertical scrollbar down the number of pixels given as the parameter. The
                <methodname>scrollLeft()</methodname> scrolls a horizontal scrollbar by
                the given number of pixels.
            </para>
        </section>

        <section xml:id="testbench.development.notifications">
            <title>Testing Notifications</title>

            <para>
                When testing notifications, you will need to close the notification box.
                You need to get hold of the
                <interfacename>TestBenchElementCommands</interfacename> interface from the
                <classname>WebElement</classname> of the notification element with
                <methodname>testBenchElement(WebElement)</methodname>. The
                <methodname>closeNotification()</methodname> method in the interface
                closes the notification.
            </para>
        </section>

        <section xml:id="testbench.development.contextmenu">
            <title>Testing Context Menus</title>

            <para>
                Opening context menus require special handling. You need to create a
                Selenium <classname>Actions</classname> object to perform a context click
                on a <classname>WebElement</classname>.
            </para>

            <para>
                In the following example, we open a context menu in a
                <classname>Table</classname> component, find an item by its caption text,
                and click it.
            </para>

            <programlisting><?pocket-size 70% ?><![CDATA[// Select the table body element
WebElement e = getDriver().findElement(
        By.className("v-table-body"));

// Perform context click action to open the context menu
new Actions(getDriver()).moveToElement(e)
        .contextClick(e).perform();

// Select "Add Comment" from the opened menu
getDriver().findElement(
        By.xpath("//*[text() = 'Add Comment']")).click();]]></programlisting>

            <para>
                The complete example is given in the
                <filename>AdvancedCommandsITCase.java</filename> example source file.
            </para>
        </section>

        <section xml:id="testbench.development.timing">
            <title>Profiling Test Execution Time</title>

            <para>
                It is not just that it works, but also how long it takes. Profiling test
                execution times consistently is not trivial, as a test environment can
                have different kinds of latency and interference. For example in a
                distributed setup, timings taken on the test server would include the
                latencies between the test server, the grid hub, a grid node running the
                browser, and the web server running the application. In such a setup, you
                could also expect interference between multiple test nodes, which all
                might make requests to a shared application server and possibly also share
                virtual machine resources.
            </para>

            <para>
                Furthermore, in Vaadin applications, there are two sides which need to be
                profiled: the server-side, on which the application logic is executed, and
                the client-side, where it is rendered in the browser. Vaadin TestBench
                includes methods for measuring execution time both on the server-side and
                the client-side.
            </para>

            <para>
                The <interfacename>TestBenchCommands</interfacename> interface offers the
                following methods for profiling test execution time:
            </para>

            <variablelist>
                <varlistentry>
                    <term><methodname>totalTimeSpentServicingRequests()</methodname></term>
                    <listitem>
                        <para>
                            Returns the total time (in milliseconds) spent servicing requests in the
                            application on the server-side. The timer starts when you
                            first navigate to the application and hence start a new
                            session. The time passes only when servicing requests for the
                            particular session.  The timer is shared in the servlet
                            session, so if you have, for example, multiple portlets in the
                            same application (session), their execution times will be
                            included in the same total.

                            <!-- TODO Vaadin 7: windows to roots -->
                        </para>

                        <para>
                            Notice that if you are also interested in the client-side
                            performance for the last request, you must call the
                            <methodname>timeSpentRenderingLastRequest()</methodname>
                            before calling this method. This is due to the fact that this
                            method makes an extra server request, which will cause an
                            empty response to be rendered.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><methodname>timeSpentServicingLastRequest()</methodname></term>
                    <listitem>
                        <para>
                            Returns the time (in milliseconds) spent servicing the last
                            request in the application on the server-side. Notice that not
                            all user interaction through the WebDriver cause server
                            requests.
                        </para>

                        <para>
                            As with the total above, if you are also interested in the
                            client-side performance for the last request, you must call
                            the <methodname>timeSpentRenderingLastRequest()</methodname>
                            before calling this method.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><methodname>totalTimeSpentRendering()</methodname></term>
                    <listitem>
                        <para>
                            Returns the total time (in milliseconds) spent rendering the
                            user interface of the application on the client-side, that is,
                            in the browser. This time only passes when the browser is
                            rendering after interacting with it through the WebDriver. The
                            timer is shared in the servlet session, so if you have, for
                            example, multiple portlets in the same application (session),
                            their execution times will be included in the same total.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><methodname>timeSpentRenderingLastRequest()</methodname></term>
                    <listitem>
                        <para>
                            Returns the time (in milliseconds) spent rendering user
                            interface of the application after the last server
                            request. Notice that not all user interaction through the
                            WebDriver cause server requests.
                        </para>

                        <para>
                            If you also call the
                            <methodname>timeSpentServicingLastRequest()</methodname> or
                            <methodname>totalTimeSpentServicingRequests()</methodname>,
                            you should do so before calling this method. The methods cause
                            a server request, which will zero the rendering time measured
                            by this method.
                        </para>
                    </listitem>
                </varlistentry>
            </variablelist>

            <para>
                 Generally, only interaction with fields in the
                 <emphasis>immediate</emphasis> mode cause server requests. This includes
                 button clicks. Some components, such as <classname>Table</classname>,
                 also cause requests otherwise, such as when loading data while
                 scrolling. Some interaction could cause multiple requests, such as when
                images are loaded from the server as the result of user interaction.
            </para>
            
            <para>
                The following example is given in the
                <filename>VerifyExecutionTimeITCase.java</filename> file under the
                TestBench examples.
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[@Test
public void verifyServerExecutionTime() throws Exception {
    openCalculator();

    // Get start time on the server-side
    long currentSessionTime = testBench(getDriver())
            .totalTimeSpentServicingRequests();

    // Interact with the application
    calculateOnePlusTwo();

    // Calculate the passed processing time on the serve-side
    long timeSpentByServerForSimpleCalculation = testBench()
        .totalTimeSpentServicingRequests() - currentSessionTime;

    // Report the timing
    System.out.println("Calculating 1+2 took about "
            + timeSpentByServerForSimpleCalculation
            + "ms in servlets service method.");

    // Fail if the processing time was critically long
    if (timeSpentByServerForSimpleCalculation > 30) {
        fail("Simple calculation shouldn't take "
             + timeSpentByServerForSimpleCalculation + "ms!");
    }

    // Do the same with rendering time
    long totalTimeSpentRendering =
            testBench().totalTimeSpentRendering();
    System.out.println("Rendering UI took " +
            totalTimeSpentRendering + "ms");
    if (timeSpentByServerForSimpleCalculation > 400) {
        fail("Rendering UI shouldn't take "
             + timeSpentByServerForSimpleCalculation + "ms!");
    }

    // A regular assertion on the UI state
    assertEquals("3.0", getDriver().findElement(
                        By.id("display")).getText());
}]]></programlisting>

        </section>
    </section>

    <section xml:id="testbench.screenshots">
        <title>Taking and Comparing Screenshots</title>

        <para>
            You can take and compare screenshots with reference screenshots taken
            earlier. If there are differences, you can fail the test case.
        </para>
        
        <section xml:id="testbench.screenshots.parameters">
            <title>Screenshot Parameters</title>

            <para>
                The screenshot configuration parameters are defined with static methods in
                the <classname>com.vaadin.testbench.Parameters</classname> class.
            </para>

            <variablelist>
                <varlistentry>
                    <term><parameter>screenshotErrorDirectory</parameter> (default: <literal>null</literal>)</term>
                    <listitem>
                        Defines the directory where screenshots for failed tests or
                        comparisons are stored.
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><parameter>screenshotReferenceDirectory</parameter> (default: <literal>null</literal>)</term>
                    <listitem>
                        Defines the directory where the reference images for screenshot
                        comparison are stored.
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><parameter>captureScreenshotOnFailure</parameter> (default: <literal>true</literal>)</term>
                    <listitem>
                        Defines whether screenshots are taken whenever an assertion fails.
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><parameter>screenshotComparisonTolerance</parameter> (default: <literal>0.01</literal>)</term>
                    <listitem>
                        Screen comparison is usually not done with exact pixel values,
                        because rendering in browser often has some tiny
                        inconsistencies. Also image compression may cause small artifacts.
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><parameter>screenshotComparisonCursorDetection</parameter> (default: <literal>false</literal>)</term>
                    <listitem>
                        Some field component get a blinking cursor when they have the
                        focus. The cursor can cause unnecessary failures depending on
                        whether the blink happens to make the cursor visible or invisible
                        when taking a screenshot. This parameter enables cursor detection
                        that tries to minimize these failures.
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><parameter>maxScreenshotRetries</parameter> (default: 2)</term>
                    <listitem>
                        Sometimes a screenshot comparison may fail because the screen
                        rendering has not yet finished, or there is a blinking cursor that
                        is different from the reference screenshot. For these reasons,
                        Vaadin TestBench retries the screenshot comparison for a number of
                        times defined with this parameter.
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><parameter>screenshotRetryDelay</parameter> (default: <literal>500</literal>)</term>
                    <listitem>
                        Delay in milliseconds for making a screenshot retry when a
                        comparison fails.
                    </listitem>
                </varlistentry>
            </variablelist>

            <para>
                For example:
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[@Before
public void setUp() throws Exception {
    Parameters.setScreenshotErrorDirectory(
        "screenshots/errors");
    Parameters.setScreenshotReferenceDirectory(
        "screenshots/reference");
    Parameters.setMaxScreenshotRetries(2);
    Parameters.setScreenshotComparisonTolerance(1.0);
    Parameters.setScreenshotRetryDelay(10);
    Parameters.setScreenshotComparisonCursorDetection(true);
    Parameters.setCaptureScreenshotOnFailure(true);
}
]]></programlisting>

        </section>

        <section xml:id="testbench.screenshots.failure">
            <title>Taking Screenshots on Failure</title>

            <!-- TODO: What is wrong with this? -->

            <para>
                Vaadin TestBench takes screenshots automatically when a test fails, if the
                <parameter>captureScreenShotOnFailure</parameter> is enabled in TestBench
                parameters. The screenshots are written to the error directory defined
                with the <parameter>screenshotErrorDirectory</parameter> parameter.
            </para>

            <para>
                You need to have the following in the setup method:
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[@Before
public void setUp() throws Exception {
    Parameters.setScreenshotErrorDirectory("screenshots/errors");
    Parameters.setCaptureScreenshotOnFailure(true);
    ...
}]]></programlisting>

        </section>

        <section xml:id="testbench.screenshot.comparison">
            <title>Taking Screenshots for Comparison</title>

            <para>
                Vaadin TestBench allows taking screenshots of the web browser window with
                the <methodname>compareScreen()</methodname> command in the
                <classname>TestBenchCommands</classname> interface. The method has a
                number of variants.
            </para>

            <para>
                The <methodname>compareScreen(<classname>File</classname>)</methodname>
                takes a <classname>File</classname> object pointing to the reference
                image. In this case, a possible error image is written to the error
                directory with the same file name. You can get a file object to a
                reference image with the static
                <methodname>ImageFileUtil.getReferenceScreenshotFile()</methodname> helper
                method.
            </para>

            <programlisting><?pocket-size 75% ?><![CDATA[assertTrue("Screenshots differ",
           testBench(driver).compareScreen(
               ImageFileUtil.getReferenceScreenshotFile(
                   "myshot.png")));]]></programlisting>

            <para>
                The <methodname>compareScreen(<classname>String</classname>)</methodname>
                takes a base name of the screenshot. It is appended with browser
                identifier and the file extension.
            </para>

            <programlisting><?pocket-size 75% ?><![CDATA[assertTrue(testBench(driver).compareScreen("tooltip"));]]></programlisting>

            <para>
                The <methodname>compareScreen(<classname>BufferedImage</classname>,
                <classname>String</classname>)</methodname> allows keeping the reference
                image in memory. An error image is written to a file with a name
                determined from the base name given as the second parameter.
            </para>

            <para>
                Screenshots taken with the <methodname>compareScreen()</methodname> method
                are compared to a reference image stored in the reference image folder. If
                differences are found (or the reference image is missing), the comparison
                method returns <literal>false</literal> and stores the screenshot in the
                error folder. It also generates an HTML file that highlights the differing
                regions.
            </para>

            <section xml:id="testbench.screenshot.comparison.error-images">
                <title>Screenshot Comparison Error Images</title>

                <para>
                    Screenshots with errors are written to the error folder, which is
                    defined with the <parameter>screenshotErrorDirectory</parameter>
                    parameter described in <xref
                    linkend="testbench.screenshots.parameters"/>.
                </para>

                <para>
                    For example, the error caused by a missing reference image could be
                    written to
                    <filename>screenshot/errors/tooltip_firefox_12.0.png</filename>. The
                    image is shown in <xref
                    linkend="figure.testbench.screenshot.comparison.error-images.calc"/>.
                </para>

                <figure xml:id="figure.testbench.screenshot.comparison.error-images.calc">
                    <title>A screenshot taken by a test run</title>
                    <mediaobject>
                        <imageobject role="html">
                            <imagedata align="center" fileref="img/testbench/screenshots/tt-screenshot-calc.png"/>
                        </imageobject>
                        <imageobject role="fo">
                            <imagedata scale="60" smallscale="80%" align="center" fileref="img/testbench/screenshots/tt-screenshot-calc.png"/>
                        </imageobject>
                    </mediaobject>
                </figure>

                <para>
                    Screenshots cover the visible page area in the browser. The size of
                    the browser is therefore relevant for screenshot comparison. The
                    browser is normally sized with a predefined default size. You can set
                    the size of the browser window with, for example,
                    <literal>driver.manage().window().setSize(new Dimension(1024,
                    768));</literal> in the <literal>@Before</literal> method. The size
                    includes any browser chrome, so the actual screenshot size will be
                    smaller.
                </para>
            </section>

            <section xml:id="testbench.screenshot.comparison.reference-images">
                <title>Reference Images</title>

                <para>
                    Reference images are expected to be found in the reference image
                    folder, as defined with the
                    <parameter>screenshotReferenceDirectory</parameter> parameter described in
                    <xref linkend="testbench.screenshots.parameters"/>.  To create a
                    reference image, just copy a screenshot from the
                    <filename>errors/</filename> directory to the
                    <filename>reference/</filename> directory.
                </para>

                <para>
                    For example:
                </para>

                <screen><prompt>$</prompt> <command>cp</command> <parameter>screenshot/errors/tooltip_firefox_12.0.png</parameter> <parameter>screenshot/reference/</parameter></screen>

                <para>
                    Now, when the proper reference image exists, rerunning the test
                    outputs success:
                </para>

                <screen><prompt>$</prompt> <command>java</command> ...
JUnit version 4.5
.
Time: 18.222

OK (1 test)</screen>

                <para>
                    You can also supply multiple versions of the reference images by
                    appending an underscore and an index to the filenames. For example:
                </para>

                <screen>tooltip_firefox_12.0.png
tooltip_firefox_12.0_1.png
tooltip_firefox_12.0_2.png</screen>

                <para>
                    This can be useful in certain situations when there actually are more
                    than one "correct" reference.
                </para>
            </section>

            <section xml:id="testbench.screenshots.comparison.masked">
                <title>Masking Screenshots</title>

                <para>
                    You can make masked screenshot comparison with reference images that
                    have non-opaque regions. Non-opaque pixels in the reference image,
                    that is, ones with less than 1.0 value, are ignored in the screenshot
                    comparison.
                </para>
            </section>

            <section xml:id="testbench.screenshot.comparison.visualization">
                <title>Visualization of Differences in Screenshots with Highlighting</title>

                <para>
                    Vaadin TestBench supports advanced difference visualization between a
                    captured screenshot and the reference image. A difference report is
                    written to a HTML file that has the same name as the failed
                    screenshot, but with <filename>.html</filename> suffix. The reports are
                    written to the same <filename>errors/</filename> folder as the
                    screenshots from the failed tests.
                </para>

                <para>
                    The differences in the images are highlighted with blue
                    rectangles. Moving the mouse pointer over a square shows the
                    difference area as it appears in the reference image. Clicking the
                    image switches the entire view to the reference image and back. Text
                    "<guilabel>Image for this run</guilabel>" is displayed in the top-left
                    corner to identify the currently displayed screenshot.
                </para>

                <para>
                    <xref
                    linkend="figure.testbench.screenshot.comparison.visualization.highlighting"/>
                    shows a difference report with three differences. Date fields are a
                    typical cause of differences in screenshots.
                </para>

                <figure xml:id="figure.testbench.screenshot.comparison.visualization.highlighting">
                    <title>The reference image and a highlighed error image</title>
                    <mediaobject>
                        <imageobject role="html">
                            <imagedata align="center" fileref="img/testbench/screenshots/tt-screenshot-comparison-1.png"/>
                        </imageobject>
                        <imageobject role="fo">
                            <imagedata scale="100" smallscale="80%" align="center" fileref="img/testbench/screenshots/tt-screenshot-comparison-1.png"/>
                        </imageobject>
                    </mediaobject>
                    <mediaobject>
                        <imageobject role="html">
                            <imagedata align="center" fileref="img/testbench/screenshots/tt-screenshot-comparison-2.png"/>
                        </imageobject>
                        <imageobject role="fo">
                            <imagedata scale="100" smallscale="80%" align="center" fileref="img/testbench/screenshots/tt-screenshot-comparison-2.png"/>
                        </imageobject>
                    </mediaobject>
                </figure>
            </section>
        </section>

        <section xml:id="testbench.screenshot.comparison.practices">
            <title>Practices for Handling Screenshots</title>

            <para>
                Access to the screenshot reference image directory should be arranged
                so that a developer who can view the results can copy the valid images
                to the reference directory. One possibility is to store the reference
                images in a version control system and check-out them to the
                <filename>reference/</filename> directory.
            </para>

            <para>
                A build system or a continuous integration system can be configured to
                automatically collect and store the screenshots as build artifacts.
            </para>
        </section>


        <section xml:id="testbench.screenshot.compatibility">
            <title>Known Compatibility Problems</title>

            <variablelist>
                <varlistentry>
                    <term><para>Screenshots when running Internet Explorer 9 in Compatibility Mode</para></term>
                    <listitem>
                        <para>
                            Internet Explorer prior to version 9 adds a two-pixel border
                            around the content area. Version 9 no longer does this and as
                            a result screenshots taken using Internet Explorer 9 running
                            in compatibility mode (IE7/IE8) will include the two pixel
                            border, contrary to what the older versions of Internet
                            Explorer do.
                        </para>
                    </listitem>
                </varlistentry>
            </variablelist>
        </section>            
    </section>

    <section xml:id="testbench.grid">
        <title>Running Tests in a Distributed Environment</title>

        <para>
            A distributed test environment consists of a grid hub and a number of test
            nodes. The hub listens to calls from test runners and delegates them to the
            grid nodes. Different nodes can run on different operating system platforms
            and have different browsers installed.
        </para>

        <para>
            A basic distributed installation was covered in <xref
            linkend="testbench.installation.distributed"/>.
        </para>

        <section xml:id="testbench.grid.remote">
            <title>Running Tests Remotely</title>

            <para>
                Remote tests are just like locally executed JUnit tests, except instead of
                using a browser driver, you use a <classname>RemoteWebDriver</classname>
                that can connect to the hub. The hub delegates the connection to a grid
                node with the desired capabilities, that is, which browsers are installed
                in a suitable node. The capabilities are described with a
                <classname>DesiredCapabilities</classname> object.
            </para>

            <para>
                For example, in the example tests given in the <filename>example</filename>
                folder, we create and use a remote driver as follows:
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[@Test
public void testRemoteWebDriver() throws MalformedURLException {
    // Require Firefox in the test node
    DesiredCapabilities capability =
        DesiredCapabilities.firefox();

    // Create a remote web driver that connects to a hub
    // running in the local host
    WebDriver driver = TestBench.createDriver(
        new RemoteWebDriver(new URL(
            "http://localhost:4444/wd/hub"), capability));

    // Then use it to run a test as you would use any web driver
    try {
        driver.navigate().to(
            "http://demo.vaadin.com/sampler#TreeActions");
        WebElement e = driver.findElement(By.xpath(
            "//div[@class='v-tree-node-caption']"+
            "/div[span='Desktops']"));
        new Actions(driver).moveToElement(e).contextClick(e)
            .perform();
    } finally {
        driver.quit();
    }
}
]]></programlisting>

            <para>
                Please see the API documentation of the
                <classname>DesiredCapabilities</classname> class for a complete list of
                supported capabilities.
            </para>

            <para>
                Running the example requires that the hub service and the nodes are
                running. Starting them is described in the subsequent sections. Please
                refer to <link
                xlink:href="http://seleniumhq.org/docs/07_selenium_grid.html">Selenium
                documentation</link> for more detailed information.
            </para>
        </section>

        <section xml:id="testbench.grid.hub">
            <title>Starting the Hub</title>
            
            <para>
                The TestBench grid hub listens to calls from test runners and delegates
                them to the grid nodes. The grid hub service is included in the Vaadin
                TestBench JAR and you can start it with the following command:
            </para>

            <screen><prompt>$</prompt> <command>java</command> -jar vaadin-testbench-standalone-&version.testbench;.jar \
       -role hub</screen>

            <para>
                You can open the control interface of the hub also with a web
                browser. Using the default port, just open URL
                <uri>http://localhost:4444/</uri>. Once you have started one or more grid
                nodes, as instructed in the next section, the "console" page displays a
                list of the grid nodes with their browser capabilities.
            </para>
        </section>

        <section xml:id="testbench.grid.node-configuration">
            <title>Node Service Configuration</title>

            <para>
                Test nodes can be configured with command-line options, as described
                later, or in a configuration file in JSON format. If no configuration file
                is provided, a default configuration is used.
            </para>

            <para>
                A node configuration file is specified with the
                <parameter>-nodeConfig</parameter> parameter to the node service, for
                example as follows:
            </para>

            <screen><prompt>$</prompt> <command>java</command> -jar vaadin-testbench-standalone-&version.testbench;.jar
       -role node -nodeConfig <parameter>nodeConfig.json</parameter></screen>

            <para>
                See <xref linkend="testbench.grid.node"/> for further details on starting
                the node service.
            </para>

            <section xml:id="testbench.grid.node-configuration.format">
                <title>Configuration File Format</title>

                <para>
                    The test node configuration file follows the JSON format, which
                    defines nested associative maps. An associative map is defined as a
                    block enclosed in curly braces (<literal>{}</literal>). A mapping is a
                    key-value pair separated with a colon (<literal>:</literal>). A key is
                    a string literal quoted with double quotes
                    (<literal>"key"</literal>). The value can be a string literal, list,
                    or a nested associative map. A list a comma-separated sequence
                    enclosed within square brackets (<literal>[]</literal>).
                </para>

                <para>
                    The top-level associative map should have two associations:
                    <literal>capabilities</literal> (to a list of associative maps) and
                    <literal>configuration</literal> (to a nested associative map).
                </para>

                <programlisting><?pocket-size 75% ?>{
  "capabilities":
    [
      {
        "browserName": "<parameter>firefox</parameter>",
        ...
      },
      ...
    ],
  "configuration":
  {
    "port": 5555,
    ...
  }
}</programlisting>

                <para>
                    A complete example is given later.
                </para>
            </section>

            <section xml:id="testbench.grid.node-configuration.capabilities">
                <title>Browser Capabilities</title>

                <para>
                    The browser capabilities are defined as a list of associative maps as
                    the value of the <literal>capabilities</literal> key. The capabilities
                    can also be given from command-line using the
                    <parameter>-browser</parameter> parameter, as described in <xref
                    linkend="testbench.grid.node"/>.
                </para>

                <para>
                    The keys in the map are the following:
                </para>

                <variablelist>
                    <varlistentry>
                        <term><parameter>platform</parameter></term>
                        <listitem>
                            The operating system platform of the test node. Can be
                            <literal>WINDOWS</literal>, <literal>LINUX</literal>, or
                            <literal>MAC</literal>.
                        </listitem>
                    </varlistentry>
                    <varlistentry>
                        <term><parameter>browserName</parameter></term>
                        <listitem>
                            A browser identifier, any of: <literal>android</literal>,
                            <literal>chrome</literal>, <literal>firefox</literal>,
                            <literal>htmlunit</literal>, <literal>internet explorer</literal>,
                            <literal>iphone</literal>, <literal>opera</literal>.
                    </listitem>
                    </varlistentry>
                    <varlistentry>
                        <term><parameter>maxInstances</parameter></term>
                        <listitem>
                            The maximum number of browser instances of this type open at
                            the same time for parallel testing.
                        </listitem>
                    </varlistentry>
                    <varlistentry>
                        <term><parameter>version</parameter></term>
                        <listitem>
                            The major version number of the browser.
                        </listitem>
                    </varlistentry>
                    <varlistentry>
                        <term><parameter>seleniumProtocol</parameter></term>
                        <listitem>
                            This should be <literal>WebDriver</literal> for WebDriver use, or
                            <literal>Selenium</literal> for tests in the HTML format.
                        </listitem>
                    </varlistentry>
                    <varlistentry>
                        <term><parameter>firefox_binary</parameter></term>
                        <listitem>
                            Full path and file name of the Firefox executable. This is
                            typically needed if you have Firefox ESR installed in a
                            location that is not in the system path.
                        </listitem>
                    </varlistentry>
                </variablelist>
            </section>

            <section xml:id="testbench.grid.node-configuration.server">
                <title>Server Configuration</title>

                <para>
                    The node service configuration is defined as a nested associative map
                    as the value of the <literal>configuration</literal> key. The
                    configuration parameters can also be given as command-line parameters
                    to the node service, as described in <xref linkend="testbench.grid.node"/>.
                </para>

                <para>
                    See the following example for a typical server configuration.
                </para>
            </section>

            <section xml:id="testbench.grid.node-configuration.example">
                <title>Example Configuration</title>

                <programlisting><?pocket-size 75% ?>{
  "capabilities":
    [
      {
        "browserName": "<parameter>firefox</parameter>",
        "maxInstances": <parameter>5</parameter>,
        "seleniumProtocol": "<parameter>WebDriver</parameter>",
        "version": "<parameter>10</parameter>",
        "firefox_binary": "<parameter>/path/to/firefox10</parameter>"
      },
      {
        "browserName": "<parameter>firefox</parameter>",
        "maxInstances": <parameter>5</parameter>,
        "version": "<parameter>16</parameter>",
        "firefox_binary": "<parameter>/path/to/firefox16</parameter>"
      },
      {
        "browserName": "<parameter>chrome</parameter>",
        "maxInstances": <parameter>5</parameter>,
        "seleniumProtocol": "<parameter>WebDriver</parameter>"
      },
      {
        "platform": "<parameter>WINDOWS</parameter>",
        "browserName": "<parameter>internet explorer</parameter>",
        "maxInstances": <parameter>1</parameter>,
        "seleniumProtocol": "<parameter>WebDriver</parameter>"
      }
    ],
  "configuration":
  {
    "proxy": "org.openqa.grid.selenium.proxy.DefaultRemoteProxy",
    "maxSession": 5,
    "port": 5555,
    "host": ip,
    "register": true,
    "registerCycle": 5000,
    "hubPort": 4444
  }
}</programlisting>
            </section>
        </section>

        <section xml:id="testbench.grid.node">
            <title>Starting a Grid Node</title>

            <para>
                A TestBench grid node listens to calls from the hub and is capable of
                opening a browser. The grid node service is included in the Vaadin
                TestBench JAR and you can start it with the following command:
            </para>

            <screen><prompt>$</prompt> <command>java</command> -jar \
       vaadin-testbench-standalone-&version.testbench;.jar \
       -role node \
       -hub <parameter>http://localhost:4444/grid/register</parameter></screen>

            <para>
                The node registers itself in the grid hub. You need to give the address of
                the hub either with the <parameter>-hub</parameter> parameter or in the
                node configuration file as described in <xref
                linkend="testbench.grid.node-configuration"/>.
            </para>

            <para>
                You can run one grid node in the same host as the hub, as is done in the
                example above with the localhost address. In such case notice that, at
                least in OS X, you may need to duplicate the JAR to a separate copy to use
                it to run a grid node service.
            </para>

            <section xml:id="testbench.grid.node.browser-capabilities">
                <title>Browser Capabilities</title>

                <para>
                    The browsers installed in the node can be defined either with a
                    command-line parameter or with a configuration file in JSON format, as
                    described in <xref linkend="testbench.grid.node-configuration"/>.
                </para>

                <para>
                    On command-line, you can issue a <parameter>-browser</parameter> option to
                    define the browser capabilities. It must be followed by a comma-separated
                    list of property-value definitions, such as the following:
                </para>

                <screen>-browser "browserName=firefox,version=10,firefox_binary=/path/to/firefox10" \
-browser "browserName=firefox,version=16,firefox_binary=/path/to/firefox16" \
-browser "browserName=chrome,maxInstances=5" \
-browser "browserName=internet explorer,maxInstances=1,platform=WINDOWS"</screen>

                <para>
                    The configuration properties are described in <xref
                    linkend="testbench.grid.node-configuration"/>.
                </para>
            </section>

            <section xml:id="testbench.grid.node.browserdriver">
                <title>Browser Driver Parameters</title>

                <para>
                    If you use Chrome or Internet Explorer, their remote driver
                    executables must be in the system path (in the <literal>PATH</literal>
                    environment variable) or be given with a command-line parameter to the
                    node service:
                </para>

                <variablelist>
                    <varlistentry>
                        <term>Internet Explorer</term>
                        <listitem>
                            <parameter>-Dwebdriver.ie.driver=C:\path\to\IEDriverServer.exe</parameter>
                        </listitem>
                    </varlistentry>
                    <varlistentry>
                        <term>Google Chrome</term>
                        <listitem>
                            <parameter>-Dwebdriver.chrome.driver=/path/to/ChromeDriver</parameter>
                        </listitem>
                    </varlistentry>
                </variablelist>
            </section>
        </section>

        <section xml:id="testbench.grid.mobile">
            <title>Mobile Testing</title>

            <para>
                Vaadin TestBench includes an iPhone and an Android driver, with which you
                can test on mobile devices. The tests can be run either in a device or in
                an emulator/simulator.
            </para>

            <para>
                The actual testing is just like with any WebDriver, using either the
                <classname>IPhoneDriver</classname> or the
                <classname>AndroidDriver</classname>. The Android driver assumes that the
                hub (<filename>android-server</filename>) is installed in the emulator and
                forwarded to port 8080 in localhost, while the iPhone driver assumes port
                3001. You can also use the <classname>RemoteWebDriver</classname> with
                either the <methodname>iphone()</methodname> or the
                <methodname>android()</methodname> capability, and specify the hub URI
                explicitly.
            </para>

            <para>
                The mobile testing setup is covered in detail in the Selenium
                documentation for both the <link
                xlink:href="http://code.google.com/p/selenium/wiki/IPhoneDriver">IPhoneDriver</link>
                and the <link
                xlink:href="http://code.google.com/p/selenium/wiki/AndroidDriver">AndroidDriver</link>.
             </para>
        </section>
    </section>

    <section xml:id="testbench.headless">
        <title>Headless Testing</title>
        
        <para>
            TestBench (3.1 and later) supports fully-featured headless testing with
            PhantomJS (<link
            xlink:href="http://phantomjs.org">http://phantomjs.org</link>), a headless
            browser based on WebKit. It has fast native support for various web standards:
            JavaScript, DOM handling, CSS selector, JSON, Canvas, and SVG.
        </para>

        <para>
            Headless testing using PhantomJS allows for around 15% faster test execution
            without having to start a graphical web browser, even when performing
            screenshot-based testing! This also makes it possible to run full-scale
            functional tests on the front-end directly on a build server, without the need
            to install any web browsers.
        </para>

        <para>
            It is usually best to use a graphical browser to develop the test cases, as it
            is possible to see interactively what happens while the tests are being
            executed.  Once the tests are working correctly in a graphical browser, you
            can migrate them to run on the PhantomJS headless browser.
        </para>
            
        <section xml:id="testbench.headless.running">
            <title>Basic Setup for Running Headless Tests</title>
            
            <para>
                The only set up required is to install the PhantomJS binary. Follow the
                instructions for your operating system at <link
                xlink:href="http://phantomjs.org/download.html">PhantomJS download
                page</link>, and place the binary in the system path.
            </para>
                
            <para>
                The PhantomJSDriver dependency is already included in Vaadin TestBench.
            </para>

            <section xml:id="testbench.headless.running.createwebdriver">
                <title>Creating a Headless WebDriver Instance</title>
                
                <para>
                    Creating an instance of the <classname>PhantomJSDriver</classname> is just
                    as easy as creating an instance of <classname>FirefoxDriver</classname>.
                </para>
                
                <programlisting><?pocket-size 65% ?><![CDATA[setDriver(TestBench.createDriver(
    new PhantomJSDriver(DesiredCapabilities.phantomjs())));]]></programlisting>

                <para>
                    Some tests may fail because of the small default window size in
                    PhantomJS. Such tests are, for example, tests containing elements that
                    pop up and might go off-screen when the window is small. To make them
                    work better, specify a size for the window:
                </para>

                <programlisting><?pocket-size 75% ?><![CDATA[getDriver().manage().window().setSize(
        new Dimension(1024, 768));]]></programlisting>
        	
                <para>
                    Nothing else is needed to run tests headlessly.
                </para>
            </section>
        </section>

        <section xml:id="testbench.headless.grid">
            <title>Running Headless Tests in a Distributed Environment</title>
            
            <para>
                Running PhantomJS in a distributed grid is equally easy. First, install
                PhantomJS in the nodes by following the instructions in <xref
                linkend="testbench.headless.running"/>. Then, start PhantomJS using the
                following command:
            </para>
            
            <programlisting><?pocket-size 65% ?><![CDATA[phantomjs --webdriver=8080 \
          --webdriver-selenium-grid-hub=http://127.0.0.1:4444]]></programlisting>
        	
            <para>
                The above will start PhantomJS in the WebDriver mode and register it with
                a grid hub running at <literal>127.0.0.1:4444</literal>. After this,
                running tests in the grid is as easy as passing
                <methodname>DesiredCapabilities.phantomjs()</methodname> to the
                <literal>RemoteWebDriver</literal> constructor.
            </para>

            <programlisting><?pocket-size 75% ?><![CDATA[setDriver(new RemoteWebDriver(
        DesiredCapabilities.phantomjs()));]]></programlisting>
        </section>
    </section>

    <section xml:id="testbench.known-issues">
        <title>Known Issues</title>

        <para>
            This section provides information and instructions on a few features that are known
            to be difficult to use or need modification to work.
        </para>

        <section xml:id="testbench.known-issues.loginform">
            <title>Testing the LoginForm</title>

            <para>
                Please note that, as of Vaadin 7, <classname>LoginForm</classname> has
                been deprecated and should no longer be used. This section is here to
                inform those still using Vaadin 6.x and testing with Vaadin TestBench.
            </para>

            <para>
                Replaying interactions in the <classname>LoginForm</classname> component
                is somewhat tricky because the identifier of the <literal>iframe</literal>
                element changes every time the application is restarted, so it can not be
                used for selecting it. The use of an iframe element means that recordings
                have to select the target frame before fields can be correctly identified.
            </para>

            <section xml:id="testbench.known-issues.loginform.recorder">
                <title>Selecting a Frame in the Recorder</title>

                <para>
                    Selecting the correct frame in the recorder can be done by modifying
                    the <parameter>target</parameter> of the recorded
                    <command>selectFrame</command> command. One way to select the correct
                    frame is to specify its 0-based index in the selector, such as
                    "<literal>index=2</literal>".
                </para>

                <para>
                    Another way is to specify an XPath selector for the
                    <literal>iframe</literal>. In this case it helps if you can specify a
                    component ID for the <classname>LoginForm</classname> component. In
                    the following XPath selector example, the component ID of the
                    <classname>LoginForm</classname> is "login":
                </para>

                <programlisting><![CDATA[xpath=//id("login")//iframe]]></programlisting>
            </section>

            <section xml:id="testbench.known-issues.loginform.junit">
                <title>Selecting a Frame in JUnit Code</title>

                <para>
                    Selecting the correct frame in JUnit code by index number can be done
                    as follows:
                </para>

                <programlisting><![CDATA[// Select frame by its 0-based index
getDriver().switchTo().frame(2);]]></programlisting>

                <para>
                    Or by the XPath with:
                </para>

                <programlisting><![CDATA[WebElement frame = getDriver().
    findElement(By.xpath("//id('login')//iframe"));
getDriver().switchTo().frame(frame);]]></programlisting>
            </section>
        </section>

        <section xml:id="testbench.known-issues.asserttextpresent">
            <title>Using <methodname>assertTextPresent</methodname> and <methodname>assertTextNotPresent</methodname></title>

            <para>
                The <methodname>assertTextNotPresent</methodname> and <methodname>assertTextNotPresent</methodname>
                methods in TestBench Recorder are problematic in that they do not respect CSS rules that hide
                elements (e.g. <literal>display: none;</literal>). This means that you might have trouble
                confirming that text is or is not present.
            </para>
            <para>
                This will be fixed in a future release, but until then a better, albeit more complex, strategy
                for testing whether a string is present on screen is to use the
                <methodname>assertElementPresent</methodname> method with an XPath selector as follows:
                <programlisting><![CDATA[xpath=//div[contains(@style, "display: none")]//div[contains(text(),"HIDDEN TEXT")]]]></programlisting>
            </para>
        </section>

        <section xml:id="testbench.known-issues.upload">
            <title>Exporting Recordings of the <classname>Upload</classname> Component</title>

            <para>
                Exporting recordings of the <classname>Upload</classname> component exports one piece of
                unnecessary code that makes replay fail. Whenever you record a file upload, remember to 
                remove the call to <methodname>clear()</methodname> as upload fields are special fields
                that cannot be cleared. Also make sure that the replay window is wide enough for the upload
                button to be visible (see <methodname>driver.resizeViewPortTo()</methodname>), otherwise you
                will get an exception when running the test.
            </para>
        </section>

        <section xml:id="testbench.known-issues.firefox-mac">
            <title>Running Firefox Tests on Mac OS X</title>

            <para>
                Firefox needs to have focus in the main window for any focus events to be
                triggered. This sometimes causes problems if something interferes with the
                focus. For example, a <classname>TextField</classname> that has an input
                prompt relies on the JavaScript <methodname>onFocus()</methodname> event
                to clear the prompt when the field is focused.
            </para>

            <para>
                The problem occurs when OS X considers the Java process of an application
                using TestBench (or the node service) to have a native user interface
                capability, as with AWT or Swing, even when they are not used. This causes
                the focus to switch from Firefox to the process using TestBench, causing
                tests requiring focus to fail. To remedy this problem, you need to start
                the JVM in which the tests are running with the
                <parameter>-Djava.awt.headless=true</parameter> parameter to disable the
                user interface capability of the Java process.
            </para>

            <para>
                Note that the same problem is present also when debugging tests with
                Firefox. We therefore recommend using Chrome for debugging tests, unless
                Firefox is necessary.
            </para>
        </section>
    </section>
</chapter>

<!-- Keep this comment at the end of the file
Local variables:
mode: xml
sgml-omittag:nil
sgml-shorttag:nil
sgml-namecase-general:nil
sgml-general-insert-case:lower
sgml-minimize-attributes:nil
sgml-always-quote-attributes:t
sgml-indent-step:4
sgml-indent-data:t
sgml-parent-document:nil
sgml-exposed-tags:nil
sgml-local-catalogs:("/etc/sgml/catalog" "/usr/share/xemacs21/xemacs-packages/etc/psgml-dtds/CATALOG")
sgml-local-ecat-files:("ECAT" "~/sgml/ECAT" "/usr/share/sgml/ECAT" "/usr/local/share/sgml/ECAT" "/usr/local/lib/sgml/ECAT")
End:
-->
